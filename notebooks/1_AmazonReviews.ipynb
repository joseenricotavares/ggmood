{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368cac17",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Avaliar a viabilidade de diferentes modelos de classificação de sentimento utilizando embeddings pré-treinados, com foco em desempenho preditivo e custo computacional, visando selecionar a melhor configuração para produção.\n",
    "\n",
    "As etapas conduzidas serão:\n",
    "\n",
    "1) Download e preparação dos dados e modelos base.\n",
    "\n",
    "2) Estratificação inteligente dos dados de treino e teste com base em clustering semântico, para garantir diversidade e eficiência amostral.\n",
    "\n",
    "3) Geração dos datasets vetorizados para cada modelo de embedding.\n",
    "\n",
    "4) Treinamento e avaliação de classificadores clássicos sobre os vetores gerados, com registro de resultados via MLflow.\n",
    "\n",
    "5) Análise dos resultados preditivos, com ênfase na métrica AUC sobre dados de teste.\n",
    "\n",
    "6) Avaliação do desempenho computacional dos embedders em ambiente CPU, considerando latência, memória e tempo de processamento.\n",
    "\n",
    "7) Escolha do modelo final com base em performance preditiva e custo-benefício operacional para produção.\n",
    "\n",
    "\n",
    "**Aviso: Este notebook não é conclusivo quanto à tarefa final de escolha dos modelos, dado que postumamente optamos por realizar as predições em produção sobre reviews de jogos da Steam, e não sobre os dados da Amazon utilizados nos treinos e testes até aqui. Assim, torna-se necessário um estudo específico de generalização, a ser conduzido no notebook subsequente, com vistas a avaliar a aderência dos modelos ao novo domínio e prevenir falhas oriundas de Data Drift.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab487a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a712f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import tarfile\n",
    "import sys\n",
    "import os\n",
    "import mlflow\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src import reduce_text_df_per_class, PyCaretEmbeddingClassificationTrainer, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf563f",
   "metadata": {},
   "source": [
    "## Obtendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f40db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/raw/'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "kaggle_api = KaggleApi()\n",
    "kaggle_api.authenticate()\n",
    "kaggle_api.dataset_download_files('kritanjalijain/amazon-reviews', path=data_path, unzip=True)\n",
    "\n",
    "tgz_path = os.path.join(data_path, 'amazon_review_polarity_csv.tgz')\n",
    "\n",
    "# Extrai direto no diretório, removendo o prefixo do caminho\n",
    "if os.path.exists(tgz_path):\n",
    "    with tarfile.open(tgz_path, 'r:gz') as tar:\n",
    "        for member in tar.getmembers():\n",
    "            member.name = os.path.relpath(member.name, start=member.name.split('/')[0])\n",
    "            tar.extract(member, path=data_path)\n",
    "    os.remove(tgz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9a45c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Review Polaridy Dataset\n",
      "\n",
      "Version 3, Updated 09/09/2015\n",
      "\n",
      "ORIGIN\n",
      "\n",
      "The Amazon reviews dataset consists of reviews from amazon. The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review. For more information, please refer to the following paper: J. McAuley and J. Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. RecSys, 2013.\n",
      "\n",
      "The Amazon reviews polarity dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the above dataset. It is used as a text classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\n",
      "\n",
      "\n",
      "DESCRIPTION\n",
      "\n",
      "The Amazon reviews polarity dataset is constructed by taking review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 is ignored. In the dataset, class 1 is the negative and class 2 is the positive. Each class has 1,800,000 training samples and 200,000 testing samples.\n",
      "\n",
      "The files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 or 2), review title and review text. The review title and text are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/raw/readme.txt', 'r') as f:\n",
    "    data_description = f.read()\n",
    "print(data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905624b",
   "metadata": {},
   "source": [
    "## Análise e Limpeza\n",
    "\n",
    "Verificando tamanho dos datasets, se as classes estão balanceadas, e abrindo o head com colunas renomeadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d434814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600000, 3)\n",
      "(400000, 3)\n",
      "class\n",
      "2    1800000\n",
      "1    1800000\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>an absolute masterpiece</td>\n",
       "      <td>I am quite sure any of you actually taking the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Buyer beware</td>\n",
       "      <td>This is a self-published book, and if you want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Glorious story</td>\n",
       "      <td>I loved Whisper of the wicked saints. The stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>A FIVE STAR BOOK</td>\n",
       "      <td>I just finished reading Whisper of the Wicked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>This was a easy to read book that made me want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                       review_title  \\\n",
       "0      2                     Stuning even for the non-gamer   \n",
       "1      2              The best soundtrack ever to anything.   \n",
       "2      2                                           Amazing!   \n",
       "3      2                               Excellent Soundtrack   \n",
       "4      2  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "5      2                            an absolute masterpiece   \n",
       "6      1                                       Buyer beware   \n",
       "7      2                                     Glorious story   \n",
       "8      2                                   A FIVE STAR BOOK   \n",
       "9      2                      Whispers of the Wicked Saints   \n",
       "\n",
       "                                         review_text  \n",
       "0  This sound track was beautiful! It paints the ...  \n",
       "1  I'm reading a lot of reviews saying that this ...  \n",
       "2  This soundtrack is my favorite music of all ti...  \n",
       "3  I truly like this soundtrack and I enjoy video...  \n",
       "4  If you've played the game, you know how divine...  \n",
       "5  I am quite sure any of you actually taking the...  \n",
       "6  This is a self-published book, and if you want...  \n",
       "7  I loved Whisper of the wicked saints. The stor...  \n",
       "8  I just finished reading Whisper of the Wicked ...  \n",
       "9  This was a easy to read book that made me want...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['class', 'review_title', 'review_text']\n",
    "df_train = pd.read_csv('../data/raw/train.csv', header=None, names=columns)\n",
    "df_test = pd.read_csv('../data/raw/test.csv', header=None, names=columns)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_train['class'].value_counts())\n",
    "print(df_test['class'].value_counts())\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7960f443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class             0\n",
      "review_title    207\n",
      "review_text       0\n",
      "dtype: int64\n",
      "class            0\n",
      "review_title    24\n",
      "review_text      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Verificando nulos:\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bfb46f",
   "metadata": {},
   "source": [
    "Como pretendemos processar texto com arquiteturas conhecidas, seguem alguns procedimentos úteis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fc0c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Stuning even for the non-gamer This sound trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The best soundtrack ever to anything. I'm read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazing! This soundtrack is my favorite music ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent Soundtrack I truly like this soundtr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>an absolute masterpiece I am quite sure any of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Buyer beware This is a self-published book, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Glorious story I loved Whisper of the wicked s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>A FIVE STAR BOOK I just finished reading Whisp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Whispers of the Wicked Saints This was a easy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      1  Stuning even for the non-gamer This sound trac...\n",
       "1      1  The best soundtrack ever to anything. I'm read...\n",
       "2      1  Amazing! This soundtrack is my favorite music ...\n",
       "3      1  Excellent Soundtrack I truly like this soundtr...\n",
       "4      1  Remember, Pull Your Jaw Off The Floor After He...\n",
       "5      1  an absolute masterpiece I am quite sure any of...\n",
       "6      0  Buyer beware This is a self-published book, an...\n",
       "7      1  Glorious story I loved Whisper of the wicked s...\n",
       "8      1  A FIVE STAR BOOK I just finished reading Whisp...\n",
       "9      1  Whispers of the Wicked Saints This was a easy ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenando review_title e review_text\n",
    "df_train['text'] = df_train['review_title'] + ' ' + df_train['review_text']\n",
    "df_test['text'] = df_test['review_title'] + ' ' + df_test['review_text']\n",
    "df_train.drop(columns=['review_title', 'review_text'], inplace=True)\n",
    "df_test.drop(columns=['review_title', 'review_text'], inplace=True)\n",
    "\n",
    "#Vamos trocar os valores 1 e 2 em class por 0 e 1, respectivamente,visando o retorno comum de classifiers binários.\n",
    "df_train['class'] = df_train['class'].replace(1, 0)\n",
    "df_train['class'] = df_train['class'].replace(2, 1)\n",
    "df_test['class'] = df_test['class'].replace(1, 0)\n",
    "df_test['class'] = df_test['class'].replace(2, 1)\n",
    "\n",
    "df_train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103a4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos no df_train por classe:\n",
      "       class  text\n",
      "class             \n",
      "0          0   120\n",
      "1          0    87\n",
      "\n",
      "Nulos no df_test por classe:\n",
      "       class  text\n",
      "class             \n",
      "0          0    16\n",
      "1          0     8\n"
     ]
    }
   ],
   "source": [
    "#Verificando se persistem os nulos em df_train e df_test para cada classe, após concatenarmos review_title e review_text\n",
    "print(\"Nulos no df_train por classe:\")\n",
    "print(df_train.groupby('class').apply(lambda x: x.isnull().sum()))\n",
    "print(\"\\nNulos no df_test por classe:\")\n",
    "print(df_test.groupby('class').apply(lambda x: x.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63f689",
   "metadata": {},
   "source": [
    "Vamos dropar os valores nulos que não poderão ser processados e rebalancear o dataset de treino, embora não seja aqui essencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6374e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls em df_train: class    0\n",
      "text     0\n",
      "dtype: int64\n",
      "Nulls em df_test: class    0\n",
      "text     0\n",
      "dtype: int64\n",
      "df_train balanceado:\n",
      "class\n",
      "0    1799880\n",
      "1    1799880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.dropna(subset=['text'])\n",
    "df_test = df_test.dropna(subset=['text'])\n",
    "\n",
    "#Balanceia amostra aleatoriamente min_count exemplos de cada classe\n",
    "min_count = df_train['class'].value_counts().min()\n",
    "\n",
    "df_train = (\n",
    "    df_train.groupby('class')\n",
    "            .apply(lambda x: x.sample(min_count, random_state=42))\n",
    "            .reset_index(drop=True)\n",
    ")\n",
    "print(f\"Nulls em df_train: {df_train.isnull().sum()}\")\n",
    "print(f\"Nulls em df_test: {df_test.isnull().sum()}\")\n",
    "print(\"df_train balanceado:\")\n",
    "print(df_train['class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03525827",
   "metadata": {},
   "source": [
    "Apenas por fins de segurança, dado que alguns modelos não suportam janelas muito amplas, vamos obter a estatistica descritiva de length dos reviews, para nos certificar que não ultrapassarão 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc97641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.599760e+06\n",
      "mean     7.848389e+01\n",
      "std      4.283268e+01\n",
      "min      2.000000e+00\n",
      "25%      4.200000e+01\n",
      "50%      7.000000e+01\n",
      "75%      1.080000e+02\n",
      "max      2.570000e+02\n",
      "Name: text_length, dtype: float64\n",
      "count    399976.000000\n",
      "mean         78.426493\n",
      "std          42.798440\n",
      "min           6.000000\n",
      "25%          42.000000\n",
      "50%          70.000000\n",
      "75%         108.000000\n",
      "max         230.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train['text_length'] = df_train['text'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "df_test['text_length'] = df_test['text'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "print(df_train['text_length'].describe())\n",
    "print(df_test['text_length'].describe())\n",
    "df_train.drop(columns=['text_length'], inplace=True)\n",
    "df_test.drop(columns=['text_length'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae6214",
   "metadata": {},
   "source": [
    "## Baixando modelos base para o projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4badf6c6",
   "metadata": {},
   "source": [
    "Vamos baixar modelos de embeddings incluindo, quando não a possuem, uma camada de mean pooling para obtê-los todos como Sentence Transformers, visando otimizar a latência do nosso serviço preditivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ff6572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ddcf338f0248f99b39b2537ffe594d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Baixando modelos de embedding:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando e salvando o modelo roberta-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name roberta-base. Creating a new one with mean pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando e salvando o modelo intfloat/e5-base...\n",
      "Baixando e salvando o modelo BAAI/bge-base-en-v1.5...\n",
      "Baixando e salvando o modelo sentence-transformers/all-MiniLM-L6-v2...\n",
      "Baixando e salvando o modelo sentence-transformers/all-mpnet-base-v2...\n",
      "Baixando e salvando o modelo sentence-transformers/all-MiniLM-L12-v2...\n",
      "Baixando e salvando o modelo thenlper/gte-small...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_dir = \"../models/sbert_models\"\n",
    "\n",
    "os.makedirs(embedding_dir, exist_ok=True)\n",
    "\n",
    "embedding_models = [\n",
    "    \"roberta-base\",\n",
    "    \"intfloat/e5-base\",\n",
    "    \"BAAI/bge-base-en-v1.5\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "    \"thenlper/gte-small\",\n",
    "]\n",
    "\n",
    "# Desabilita os logs do Hugging Face\n",
    "#logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
    "#logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "def save_sentence_transformer(model_name, save_dir):\n",
    "    print(f\"Baixando e salvando o modelo {model_name}...\")\n",
    "    # Carrega o modelo diretamente usando sentence-transformers\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.save(os.path.join(save_dir, model_name.split(\"/\")[-1]))  # Salva no diretório correto\n",
    "\n",
    "for model_name in tqdm(embedding_models, desc=\"Baixando modelos de embedding\"):\n",
    "    save_sentence_transformer(model_name, embedding_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed2fe9",
   "metadata": {},
   "source": [
    "## Estratificação das amostras de treino e teste\n",
    " \n",
    "Não pretendemos utilizar todos os dados para os treinos que faremos no notebook a seguir, uma vez considerado o custo computacional e temporal do processo.\n",
    "\n",
    "Optamos, assim, por um método inteligente de estratificação dos dados de treino e teste. Nossa abordagem consistirá em processar uma vez com um dos modelos mais velozes todas as linhas dos datatesets e na sequência clusterizar esses datasets com MiniBatchKMeans, sendo o número de clusters equivalente ao número de linhas resultante para cada dataset, uma vez que o objetivo é coletar exclusivamente o ponto mais próximo do centróide de cada cluster. Com essa abordagem, reamostraremos nossos dados com uma diversidade semântica maximizada para treino e teste, beneficiando-nos da heterogeneidade extracluster.\n",
    "\n",
    "Abaixo, embedamos ambos os dados de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae8431e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9f2d0f14e243dfa2b82df8abd39a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/14062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7d175df6a342ee860f1f527740cd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sbert = SentenceTransformer(\"../models/sbert_models/all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "df_train_embeddings = sbert.encode(\n",
    "    df_train['text'].tolist(),\n",
    "    batch_size=256,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "df_test_embeddings = sbert.encode(\n",
    "    df_test['text'].tolist(),\n",
    "    batch_size=256,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc023cfb",
   "metadata": {},
   "source": [
    "E aqui clusterizamos os datasets.\n",
    "\n",
    "Optamos por obter três datasets de treino com vistas a iterar três vezes em diferentes quantidades de dados a pipeline de treinamento e observar o quanto o modelo se beneficia de amostras maiores.\n",
    "\n",
    "Separamos uma amostra de teste relativamente grande para certificar-nos da precisão das métricas quando da avaliação.\n",
    "\n",
    "Cf. '../src/data/resample.py/' para detalhes sobre o processo adotado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b890070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing class: 0\n",
      "Class size: 1799880 → Clusters: 8999\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Processing class: 1\n",
      "Class size: 1799880 → Clusters: 8999\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Final reduced dataset size: (17998, 2)\n",
      "class\n",
      "1    8999\n",
      "0    8999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing class: 0\n",
      "Class size: 1799880 → Clusters: 17998\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Processing class: 1\n",
      "Class size: 1799880 → Clusters: 17998\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Final reduced dataset size: (35996, 2)\n",
      "class\n",
      "1    17998\n",
      "0    17998\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing class: 0\n",
      "Class size: 1799880 → Clusters: 35997\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Processing class: 1\n",
      "Class size: 1799880 → Clusters: 35997\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Final reduced dataset size: (71994, 2)\n",
      "class\n",
      "0    35997\n",
      "1    35997\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing class: 1\n",
      "Class size: 199992 → Clusters: 9999\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Processing class: 0\n",
      "Class size: 199984 → Clusters: 9999\n",
      "Fitting MiniBatchKMeans...\n",
      "\n",
      "Final reduced dataset size: (19998, 2)\n",
      "class\n",
      "0    9999\n",
      "1    9999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_amazonreviews_sample0005 = reduce_text_df_per_class(\n",
    "    df=df_train,\n",
    "    class_column=\"class\",\n",
    "    embedding_input=df_train_embeddings,\n",
    "    target_proportion= 0.005,\n",
    ")\n",
    "\n",
    "train_amazonreviews_sample0010 = reduce_text_df_per_class(\n",
    "    df=df_train,\n",
    "    class_column=\"class\",\n",
    "    embedding_input=df_train_embeddings,\n",
    "    target_proportion= 0.01,\n",
    ")\n",
    "\n",
    "train_amazonreviews_sample0020 = reduce_text_df_per_class(\n",
    "    df=df_train,\n",
    "    class_column=\"class\",\n",
    "    embedding_input=df_train_embeddings,\n",
    "    target_proportion= 0.02,\n",
    ")\n",
    "\n",
    "test_amazonreviews_sample0050 = reduce_text_df_per_class(\n",
    "    df=df_test,\n",
    "    class_column=\"class\",\n",
    "    embedding_input=df_test_embeddings,\n",
    "    target_proportion= 0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b75d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amazonreviews_sample0005.to_csv(\n",
    "    \"../data/processed/train_amazonreviews_sample0005.csv\",\n",
    "    index=False,\n",
    ")\n",
    "train_amazonreviews_sample0010.to_csv(\n",
    "    \"../data/processed/train_amazonreviews_sample0010.csv\",\n",
    "    index=False,\n",
    ")\n",
    "train_amazonreviews_sample0020.to_csv(\n",
    "    \"../data/processed/train_amazonreviews_sample0020.csv\",\n",
    "    index=False,\n",
    ")\n",
    "test_amazonreviews_sample0050.to_csv(\n",
    "    \"../data/processed/test_amazonreviews_sample0050.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e36512",
   "metadata": {},
   "source": [
    "## Gerando datasets vetorizados de treino para cada embedder\n",
    "\n",
    "Como primeira abordagem para o treinamento dos classificadores de sentimento, vamos gerar e salvar versões vetorizadas dos datasets de treino e teste com diferentes embedders. Esses vetores serão usados posteriormente em modelos clássicos de classificação, com o PyCaret facilitando sua configuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebe3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508b61cc460e4870b460dd6733251cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Modelos:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57499ae546e44d9a7a5562608f4e104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets para all-MiniLM-L12-v2:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a44a272e59842aaba415a6744e3dbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets para all-MiniLM-L6-v2:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4380bd49509a4d24adbbdd4e53bf3397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets para all-mpnet-base-v2:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c13ae6cb2384bc4896a0628b4bc829b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets para bge-base-en-v1.5:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2360d01642054be1be57000ea2393049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets para e5-base:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0330e85f6649128e1570a49cc8244f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets para gte-small:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de7d65e7c924a6b85bd3e4124f51664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets para roberta-base:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_dir = \"../models/sbert_models/\"\n",
    "data_dir = \"../data/processed/\"\n",
    "output_dir = os.path.join(data_dir, \"embedded_data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "CLASS_COL = \"class\"\n",
    "\n",
    "model_names = [m for m in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, m))]\n",
    "dataset_files = [f for f in os.listdir(data_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "for model_name in tqdm(model_names, desc=\"Modelos\"):\n",
    "    model = SentenceTransformer(os.path.join(models_dir, model_name), device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for dataset_file in tqdm(dataset_files, desc=f\"Datasets para {model_name}\", leave=False):\n",
    "        df = pd.read_csv(os.path.join(data_dir, dataset_file))\n",
    "\n",
    "        texts = df[TEXT_COL].astype(str).tolist()\n",
    "        embeddings = model.encode(texts, batch_size=256, show_progress_bar=False, normalize_embeddings=True)\n",
    "\n",
    "        emb_df = pd.DataFrame(embeddings, columns=[f\"CLS{i}\" for i in range(len(embeddings[0]))])\n",
    "        emb_df[TEXT_COL] = df[TEXT_COL]\n",
    "        emb_df[CLASS_COL] = df[CLASS_COL]\n",
    "\n",
    "        output_name = f\"{os.path.splitext(dataset_file)[0]}_{model_name}.csv\"\n",
    "        emb_df.to_csv(os.path.join(output_dir, output_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f215b",
   "metadata": {},
   "source": [
    "## Treinando e avaliando classificadores com embeddings gerados\n",
    "\n",
    "Nesta etapa, treinamos modelos clássicos de classificação utilizando os datasets vetorizados por diferentes embedders. Utilizamos o PyCaret para facilitar a configuração e comparação dos classificadores com base em desempenho (AUC), salvando os melhores modelos e suas performances sobre os conjuntos teste para análise.\n",
    "\n",
    "Todos os resultados são registrados via MLflow, conforme o código das classes nos módulos de 'src'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90bac2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8c47c37b444ce38c249c03a69f20bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets de Embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/05 00:14:35 INFO mlflow.tracking.fluent: Experiment with name 'pycaret-embeddings-classification' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "embedded_data_dir = \"../data/processed/embedded_data\"\n",
    "\n",
    "target_column  = 'class'\n",
    "drop_columns = ['text']\n",
    "\n",
    "all_files = [f for f in os.listdir(embedded_data_dir) if f.endswith('.csv')]\n",
    "train_files = [f for f in all_files if f.startswith('train')]\n",
    "test_files = [f for f in all_files if f.startswith('test')]\n",
    "\n",
    "def get_embedder_suffix(filename):\n",
    "    return filename.split('_', 3)[-1]\n",
    "\n",
    "test_lookup = {get_embedder_suffix(f): f for f in test_files}\n",
    "\n",
    "\n",
    "for train_file in tqdm(train_files, desc='Datasets de Embeddings'):\n",
    "    \n",
    "    suffix = get_embedder_suffix(train_file)\n",
    "    test_file = test_lookup.get(suffix)\n",
    "\n",
    "    embedding_model_name = suffix.replace('.csv', '')\n",
    "    train_dataset_name = train_file.replace('.csv', '')\n",
    "    df_train = pd.read_csv(os.path.join(embedded_data_dir, train_file))\n",
    "    df_test = pd.read_csv(os.path.join(embedded_data_dir, test_file))\n",
    "\n",
    "    \n",
    "    trainer = PyCaretEmbeddingClassificationTrainer(\n",
    "        train_dataset=df_train,\n",
    "        target_column=target_column,\n",
    "        drop_columns=drop_columns,  \n",
    "    )\n",
    "\n",
    "    trained_models = trainer.train()\n",
    "\n",
    "    run_ids = trainer.log_to_mlflow(\n",
    "        add_tags={\"train_dataset_name\": train_dataset_name,\n",
    "                \"embedding_model_name\": embedding_model_name,},\n",
    "    )\n",
    "\n",
    "    for run_id in run_ids:\n",
    "        \n",
    "        with mlflow.start_run(run_id=run_id):\n",
    "            model_uri = f\"runs:/{run_id}/model\"\n",
    "            model = mlflow.sklearn.load_model(model_uri) \n",
    "\n",
    "            evaluator = BinaryClassificationEvaluator(\n",
    "                model=model,\n",
    "                test_dataset_name=test_file.replace('.csv', ''),\n",
    "            )\n",
    "\n",
    "            metrics = evaluator.evaluate_sklearn_model(\n",
    "                df_test,\n",
    "                target_column=target_column,\n",
    "                drop_columns=drop_columns,\n",
    "            )\n",
    "\n",
    "            evaluator.log_to_mlflow(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb4e8b",
   "metadata": {},
   "source": [
    "## Análise dos resultados\n",
    "\n",
    "Vamos obter alguns dos metadados salvos para cada treinamento com vistas a entender qual modelo está performando melhor nos dados de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Recall</th>\n",
       "      <th>amazonreviewsPredictionTime</th>\n",
       "      <th>amazonreviewsTestAccuracy</th>\n",
       "      <th>amazonreviewsTestAUC</th>\n",
       "      <th>amazonreviewsTestF1</th>\n",
       "      <th>amazonreviewsTestPrecision</th>\n",
       "      <th>amazonreviewsTestRecall</th>\n",
       "      <th>TT _Sec_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25e222843212478db3bf82975086f4c0</td>\n",
       "      <td>9adf66be-d878-4057-9a73-ce8a148ef6c1</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9270</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.017128</td>\n",
       "      <td>0.921792</td>\n",
       "      <td>0.921792</td>\n",
       "      <td>0.919273</td>\n",
       "      <td>0.949867</td>\n",
       "      <td>0.890589</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e8a3e0394e8e4bad899abadb6997cfb8</td>\n",
       "      <td>95fc7eb1-55f8-40f1-86bc-e19ff9c8297d</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.8559</td>\n",
       "      <td>0.8568</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.029067</td>\n",
       "      <td>0.924342</td>\n",
       "      <td>0.975623</td>\n",
       "      <td>0.922358</td>\n",
       "      <td>0.947196</td>\n",
       "      <td>0.898790</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c826f0671e9a40d3a320d41447201f5c</td>\n",
       "      <td>3542dc08-ca02-4370-86c8-e664e8c5f4e3</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9329</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.8659</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.037168</td>\n",
       "      <td>0.925343</td>\n",
       "      <td>0.978061</td>\n",
       "      <td>0.924294</td>\n",
       "      <td>0.937461</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>3.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd4af64405d844408e58df3c30c2f1c3</td>\n",
       "      <td>53bcd21c-c306-4b73-8c07-1afc667cb5a0</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.9260</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.939294</td>\n",
       "      <td>0.939294</td>\n",
       "      <td>0.938074</td>\n",
       "      <td>0.957314</td>\n",
       "      <td>0.919592</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6083627879b142a79965e31c6a8f7093</td>\n",
       "      <td>00f0f3e6-2073-4975-a254-f36f70121ef3</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9516</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.028178</td>\n",
       "      <td>0.946745</td>\n",
       "      <td>0.986415</td>\n",
       "      <td>0.946139</td>\n",
       "      <td>0.957029</td>\n",
       "      <td>0.935494</td>\n",
       "      <td>1.077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id                              model_id  \\\n",
       "0  25e222843212478db3bf82975086f4c0  9adf66be-d878-4057-9a73-ce8a148ef6c1   \n",
       "1  e8a3e0394e8e4bad899abadb6997cfb8  95fc7eb1-55f8-40f1-86bc-e19ff9c8297d   \n",
       "2  c826f0671e9a40d3a320d41447201f5c  3542dc08-ca02-4370-86c8-e664e8c5f4e3   \n",
       "3  bd4af64405d844408e58df3c30c2f1c3  53bcd21c-c306-4b73-8c07-1afc667cb5a0   \n",
       "4  6083627879b142a79965e31c6a8f7093  00f0f3e6-2073-4975-a254-f36f70121ef3   \n",
       "\n",
       "  train_dataset embedding_model                  model_name  Accuracy     AUC  \\\n",
       "0    sample0020    roberta-base               SGDClassifier    0.9270  0.9772   \n",
       "1    sample0020    roberta-base          LogisticRegression    0.9279  0.9773   \n",
       "2    sample0020    roberta-base              LGBMClassifier    0.9329  0.9803   \n",
       "3    sample0020    roberta-base             RidgeClassifier    0.9442  0.9849   \n",
       "4    sample0020    roberta-base  LinearDiscriminantAnalysis    0.9516  0.9871   \n",
       "\n",
       "       F1   Kappa     MCC    Prec  Recall  amazonreviewsPredictionTime  \\\n",
       "0  0.9263  0.8540  0.8550  0.9364  0.9172                     0.017128   \n",
       "1  0.9263  0.8559  0.8568  0.9479  0.9057                     0.029067   \n",
       "2  0.9322  0.8659  0.8661  0.9425  0.9222                     0.037168   \n",
       "3  0.9431  0.8883  0.8889  0.9609  0.9260                     0.020077   \n",
       "4  0.9512  0.9033  0.9035  0.9608  0.9417                     0.028178   \n",
       "\n",
       "   amazonreviewsTestAccuracy  amazonreviewsTestAUC  amazonreviewsTestF1  \\\n",
       "0                   0.921792              0.921792             0.919273   \n",
       "1                   0.924342              0.975623             0.922358   \n",
       "2                   0.925343              0.978061             0.924294   \n",
       "3                   0.939294              0.939294             0.938074   \n",
       "4                   0.946745              0.986415             0.946139   \n",
       "\n",
       "   amazonreviewsTestPrecision  amazonreviewsTestRecall  TT _Sec_  \n",
       "0                    0.949867                 0.890589     0.581  \n",
       "1                    0.947196                 0.898790     0.780  \n",
       "2                    0.937461                 0.911491     3.427  \n",
       "3                    0.957314                 0.919592     0.565  \n",
       "4                    0.957029                 0.935494     1.077  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment_id = mlflow.get_experiment_by_name(\"pycaret-embeddings-classification\").experiment_id\n",
    "runs = client.search_runs(experiment_ids=experiment_id)\n",
    "\n",
    "mlflow_data = []\n",
    "\n",
    "for run in runs:\n",
    "    info = {}\n",
    "    \n",
    "    # run_id\n",
    "    info['run_id'] = run.info.run_id\n",
    "\n",
    "    # Tags\n",
    "    tags = run.data.tags\n",
    "    info['model_id'] = tags.get('model_id')\n",
    "    train_name = tags.get('train_dataset_name')\n",
    "    parts = train_name.split('_')\n",
    "    info['train_dataset'] = '_'.join(parts[2:3])\n",
    "    info['embedding_model'] = tags.get('embedding_model_name')\n",
    "    info['model_name'] = tags.get('model_name')\n",
    "\n",
    "    # Métricas\n",
    "    for metric_name, value in run.data.metrics.items():\n",
    "        if metric_name.startswith('test'):\n",
    "            # Procedimento necessário porque não inputamos acima o test_dataset_prefix\n",
    "            parts = metric_name.split('_')\n",
    "            new_metric_name = 'amazonreviews' + '_'.join(parts[-1:])\n",
    "            info[new_metric_name] = value\n",
    "        else:\n",
    "            info[metric_name] = value\n",
    "\n",
    "    mlflow_data.append(info)\n",
    "\n",
    "mlflow_data = pd.DataFrame(mlflow_data)\n",
    "print(mlflow_data.shape)\n",
    "mlflow_data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ced0e1",
   "metadata": {},
   "source": [
    "Levando em consideração que nossos dados estão balanceados e que consideramos testar valores diferentes de threshold para as predições, a melhor métrica para avaliação de performance no nosso caso é a Área Abaixo da Curva (AUC), e particularmente nos dados de teste ('amazonreviewsTestAUC'). \n",
    "\n",
    "A métrica 'AUC', que também avaliaremos em segundo plano, refere-se à AUC obtida pelo Pycaret quando efetuou validação cruzada sobre os dados de treino.\n",
    "\n",
    "Veremos a seguir como cada modelo performou sobre essas métricas, levando em alta consideração o embedding_model subjacente para decidir qual modelo desempenhará melhor em produção.\n",
    "\n",
    "Também consideraremos o dataset de treino utilizado por cada modelo sob a ótica do sample size referente (0.5%-2% do dataset original), para entendermos o quanto o aumento das amostras em treino afetou a qualidade das predições em teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df11f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>model_name</th>\n",
       "      <th>AUC</th>\n",
       "      <th>amazonreviewsTestAUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c604ce41a58f4cfa8402e615984f2e16</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.994121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9212f59735a3429584ba058798a3f8ad</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.994086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e61c3ec196444cb94f92d652a9072a6</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.994035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87d75ef72bad4c19946559891b71a013</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.993981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92262b01288749b6b691712e497c9781</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.993963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>512a0882ecae4f47b3e524a64f5fc987</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.993794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fdbb7d2336d344a582e4d304555711b0</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.993728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7494240945774d4885516e5565356223</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.993675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eb3845d7e64d41908941924bf006e325</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.993651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>766f158e433d4942ad6463409a6f1813</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.993626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>78970659732742dc8661e50da0f1abd6</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1497bd8e723a40d089e04f5035a5c898</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.993367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>f7b622218ef1454e94b8aa6f41c52807</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.993225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>db866db06979460b84ca82b283ff9bf5</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.993179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b3ebca80e8d34cbcbe6f383cdc61246a</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.993097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>04640f874deb4c73bca58a1a3ff35b09</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>0.992970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>f54c5bc5c20b4badaccb667433c0b02c</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.9932</td>\n",
       "      <td>0.992921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c3c694ffacfb40bf8d15d3bd898fbadf</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.992817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6083627879b142a79965e31c6a8f7093</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.986415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>019d6fa68e854e46bf39c2929828acbe</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.985671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9b65da2d4a004e3bbc62b69b7c67b2cb</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.984945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>696c3299c34d499c876d6322757c9057</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.983672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4413244dd7084cc4a8db4b79a8b13ca6</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.983352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>d0436ba95d894dc4a825a6d6177ad4e0</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.983236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>89bdbc62218641cfacb29341f33caafa</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.982760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9224e8535ee148d18170b2a05e695703</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9878</td>\n",
       "      <td>0.982534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1b92e457051a438d863b3e3265f08c63</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.981590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>914814dc3e044269886f8bf8c21e519f</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.981262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32550f058ba44024af62757ebf1967d1</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.980598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1ac1c02648654795953a57184371baa7</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.979330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>908cd9314ffa4462a69cca6c97004d47</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.979148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>c826f0671e9a40d3a320d41447201f5c</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.978061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9688ddc8a7244bac86f24d797eab5f5d</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.977933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>af2ae6846be2421a8164685abda29ba9</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.977437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1b8bf80f4da84607901a8a3b6d8cc414</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.976711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>b7d3c5f50b164203afe9b32280b40a4e</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.976441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>76ff88ad779543639ed11a4d7e0e17b0</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.975759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>e8a3e0394e8e4bad899abadb6997cfb8</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.975623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>efc9885680444a4a8f8888546a7838b3</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.975599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>e8ba1233ab5c48839610fbb8a60825b5</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.975254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1c1078d18a384a63b7a035c6c86f7072</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.972498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>d768c2b6909048198f3df2f30b0a030a</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.971171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>e9fdbfb0009b4a86a1a95a4ae8c7824b</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.968797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ab6e787e424b47959719a5a862c91ea9</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.968197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2a9bb7d6151541379a5e9cd28064ef89</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.968147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>71e98c440afc4f818c14698f59c14f9d</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.966897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>628f3347d4254d638aa328a98bb43fce</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.966897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7af05cdc302c426bb13c5fa3f451f2e4</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.966797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>24e6f1822ec04fc2806cd66d5519d8ed</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.966647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5b5ff7adce2c4b8a910ac114aad5cae7</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.966597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0d04b020cc714102bc4f86692335d92c</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.966447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>dc5a7404b3544c858c707db2a0f59a5f</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.966397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>8cd376407932496a949139403f61afcf</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.965997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>981dbc77f3c54490bf24214ac32678b7</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.964187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>28ec5960f40c418bb77a3486c6265c7a</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.963496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>d70a364654534761b568f41c0889f9ba</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.962955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7451bc4e70594f8598bc9658208e4378</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.961059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>b79e5131ee8d47a0a7c20cb4f95760ef</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.955490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6e417a2efda04e64acb8cb9fba34e305</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.955122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>35a971a51ca5480192491a4086bb5f5f</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.954459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>95cf075699414b069f7a137daeaa2aea</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.954221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>27ce2ee747e84cedbb8f6e1fb5d1dea0</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.952514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>43225071468b4255a3d29abce5848b3c</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.951660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>296b743ae1aa41a3b4b8ff4054b51975</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.950651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0532f35e7dc047bea773c09b8ec50692</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.950462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>9b4c5edb5aa846c5a933d215eed31d60</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.950326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1e5bdba39bf74b0196cbfca48850dcc2</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>0.949447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ae9383591bd647a4b37471471cbbd897</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.947908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>37f1ab135d384baf82a947a5b596f747</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.945984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>63620ab3f5464efdb441df32bea759f1</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.939444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>bd4af64405d844408e58df3c30c2f1c3</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.939294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>d382d21e48d145bd829afc7e7e02dc2f</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.938094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5004a30b8f6d4d82a4343b38b04d9b7b</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.937744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>b3b6e7c41c724c7785e4cae01cec5b4a</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.936694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2ed9e40144754e4e80dc6b4eafcc2dd8</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.936544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>a6ee75d67baa497eaba6b69e3660d54c</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.935744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>c000ce8521a54f44a945cbd2b975f01b</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.934793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>49c4633c4a8d49f7ad64e521f6268504</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.933043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>841aa8a827934dffa1e5bec5f9a806f9</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.932626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4ee98d3962254dd397d70c623254873f</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>0.931693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>90d91781574e493b9c514a5a6c091ccd</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.931643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4fde6e1d31fd4f8e9362a31e145e29bc</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.930276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>e3041d7cabe44806bfcae229d77cbcfc</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.929943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8ea0f0d56fff4ea287ad7f6777b2c453</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.929743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>561ad4da01424f59abf287aea7535542</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.929493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>62cf5d41f7684f24ad27c616a08f01e6</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>0.929113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>f6ff0c875f0a42928ceb03a3c8c571b4</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.928945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>767d787c342947be9f41eb8189571476</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>0.927763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5dadc729930244548cc7804f3631e325</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.927093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>eb31fa063fc34430af279035c150d797</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>0.925930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>25e222843212478db3bf82975086f4c0</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.921792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5ddcaa5faf8b4f19aa5bd57da33ce6bb</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.915692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>d1f01318b7484986a516735085149b9d</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.915692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>c55fad823f18446b8e6a22f2db77d63c</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.888539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>740dc87a66de4d109c1b51d89f181186</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.888339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>d7c88cd0e48b432994c61464646aa00a</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.886889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>de91dc68d9144ead80281d5c458d8da0</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.884888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>04ec95cefe524ceaa706ab784c3829cc</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.884288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17ff2831d9854291b24bf5e79d4dc1d6</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.882538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1f572a02c14d4902996822b4869673f4</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.881738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>de2c5787522d450c9e62ef822de945a5</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.880788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>df33e092e8684999b8a209f3881bb510</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9554</td>\n",
       "      <td>0.880738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2cf351c4abf845b8a72078804eb048b3</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.878688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>d8480740b4b0429d9ac50e22e4a92e70</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.877038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>181408fce98949d097800f72b399f5d9</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.872887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               run_id train_dataset    embedding_model  \\\n",
       "1    c604ce41a58f4cfa8402e615984f2e16    sample0020          gte-small   \n",
       "2    9212f59735a3429584ba058798a3f8ad    sample0010          gte-small   \n",
       "3    4e61c3ec196444cb94f92d652a9072a6    sample0020   bge-base-en-v1.5   \n",
       "4    87d75ef72bad4c19946559891b71a013    sample0005          gte-small   \n",
       "5    92262b01288749b6b691712e497c9781    sample0010   bge-base-en-v1.5   \n",
       "6    512a0882ecae4f47b3e524a64f5fc987    sample0020          gte-small   \n",
       "7    fdbb7d2336d344a582e4d304555711b0    sample0005   bge-base-en-v1.5   \n",
       "8    7494240945774d4885516e5565356223    sample0020   bge-base-en-v1.5   \n",
       "9    eb3845d7e64d41908941924bf006e325    sample0005          gte-small   \n",
       "10   766f158e433d4942ad6463409a6f1813    sample0010          gte-small   \n",
       "11   78970659732742dc8661e50da0f1abd6    sample0010   bge-base-en-v1.5   \n",
       "12   1497bd8e723a40d089e04f5035a5c898    sample0005   bge-base-en-v1.5   \n",
       "13   f7b622218ef1454e94b8aa6f41c52807    sample0010          gte-small   \n",
       "14   db866db06979460b84ca82b283ff9bf5    sample0020          gte-small   \n",
       "15   b3ebca80e8d34cbcbe6f383cdc61246a    sample0005          gte-small   \n",
       "16   04640f874deb4c73bca58a1a3ff35b09    sample0020   bge-base-en-v1.5   \n",
       "17   f54c5bc5c20b4badaccb667433c0b02c    sample0010   bge-base-en-v1.5   \n",
       "18   c3c694ffacfb40bf8d15d3bd898fbadf    sample0005   bge-base-en-v1.5   \n",
       "19   6083627879b142a79965e31c6a8f7093    sample0020       roberta-base   \n",
       "20   019d6fa68e854e46bf39c2929828acbe    sample0010       roberta-base   \n",
       "21   9b65da2d4a004e3bbc62b69b7c67b2cb    sample0005       roberta-base   \n",
       "22   696c3299c34d499c876d6322757c9057    sample0020            e5-base   \n",
       "23   4413244dd7084cc4a8db4b79a8b13ca6    sample0020            e5-base   \n",
       "24   d0436ba95d894dc4a825a6d6177ad4e0    sample0010            e5-base   \n",
       "25   89bdbc62218641cfacb29341f33caafa    sample0010            e5-base   \n",
       "26   9224e8535ee148d18170b2a05e695703    sample0005            e5-base   \n",
       "27   1b92e457051a438d863b3e3265f08c63    sample0005            e5-base   \n",
       "28   914814dc3e044269886f8bf8c21e519f    sample0020  all-mpnet-base-v2   \n",
       "29   32550f058ba44024af62757ebf1967d1    sample0010  all-mpnet-base-v2   \n",
       "30   1ac1c02648654795953a57184371baa7    sample0020  all-mpnet-base-v2   \n",
       "31   908cd9314ffa4462a69cca6c97004d47    sample0005  all-mpnet-base-v2   \n",
       "32   c826f0671e9a40d3a320d41447201f5c    sample0020       roberta-base   \n",
       "33   9688ddc8a7244bac86f24d797eab5f5d    sample0010  all-mpnet-base-v2   \n",
       "34   af2ae6846be2421a8164685abda29ba9    sample0010       roberta-base   \n",
       "35   1b8bf80f4da84607901a8a3b6d8cc414    sample0020            e5-base   \n",
       "36   b7d3c5f50b164203afe9b32280b40a4e    sample0010            e5-base   \n",
       "37   76ff88ad779543639ed11a4d7e0e17b0    sample0005       roberta-base   \n",
       "38   e8a3e0394e8e4bad899abadb6997cfb8    sample0020       roberta-base   \n",
       "39   efc9885680444a4a8f8888546a7838b3    sample0005            e5-base   \n",
       "40   e8ba1233ab5c48839610fbb8a60825b5    sample0005  all-mpnet-base-v2   \n",
       "41   1c1078d18a384a63b7a035c6c86f7072    sample0010       roberta-base   \n",
       "42   d768c2b6909048198f3df2f30b0a030a    sample0005       roberta-base   \n",
       "43   e9fdbfb0009b4a86a1a95a4ae8c7824b    sample0010          gte-small   \n",
       "44   ab6e787e424b47959719a5a862c91ea9    sample0010   bge-base-en-v1.5   \n",
       "45   2a9bb7d6151541379a5e9cd28064ef89    sample0020          gte-small   \n",
       "46   71e98c440afc4f818c14698f59c14f9d    sample0010   bge-base-en-v1.5   \n",
       "47   628f3347d4254d638aa328a98bb43fce    sample0020   bge-base-en-v1.5   \n",
       "48   7af05cdc302c426bb13c5fa3f451f2e4    sample0010          gte-small   \n",
       "49   24e6f1822ec04fc2806cd66d5519d8ed    sample0020          gte-small   \n",
       "50   5b5ff7adce2c4b8a910ac114aad5cae7    sample0020   bge-base-en-v1.5   \n",
       "51   0d04b020cc714102bc4f86692335d92c    sample0005          gte-small   \n",
       "52   dc5a7404b3544c858c707db2a0f59a5f    sample0005   bge-base-en-v1.5   \n",
       "53   8cd376407932496a949139403f61afcf    sample0005   bge-base-en-v1.5   \n",
       "54   981dbc77f3c54490bf24214ac32678b7    sample0020  all-mpnet-base-v2   \n",
       "55   28ec5960f40c418bb77a3486c6265c7a    sample0005          gte-small   \n",
       "56   d70a364654534761b568f41c0889f9ba    sample0010  all-mpnet-base-v2   \n",
       "57   7451bc4e70594f8598bc9658208e4378    sample0005  all-mpnet-base-v2   \n",
       "58   b79e5131ee8d47a0a7c20cb4f95760ef    sample0020  all-MiniLM-L12-v2   \n",
       "59   6e417a2efda04e64acb8cb9fba34e305    sample0020  all-MiniLM-L12-v2   \n",
       "60   35a971a51ca5480192491a4086bb5f5f    sample0010  all-MiniLM-L12-v2   \n",
       "61   95cf075699414b069f7a137daeaa2aea    sample0010  all-MiniLM-L12-v2   \n",
       "62   27ce2ee747e84cedbb8f6e1fb5d1dea0    sample0005  all-MiniLM-L12-v2   \n",
       "63   43225071468b4255a3d29abce5848b3c    sample0005  all-MiniLM-L12-v2   \n",
       "64   296b743ae1aa41a3b4b8ff4054b51975    sample0020   all-MiniLM-L6-v2   \n",
       "65   0532f35e7dc047bea773c09b8ec50692    sample0020   all-MiniLM-L6-v2   \n",
       "66   9b4c5edb5aa846c5a933d215eed31d60    sample0010   all-MiniLM-L6-v2   \n",
       "67   1e5bdba39bf74b0196cbfca48850dcc2    sample0010   all-MiniLM-L6-v2   \n",
       "68   ae9383591bd647a4b37471471cbbd897    sample0005   all-MiniLM-L6-v2   \n",
       "69   37f1ab135d384baf82a947a5b596f747    sample0005   all-MiniLM-L6-v2   \n",
       "70   63620ab3f5464efdb441df32bea759f1    sample0020            e5-base   \n",
       "71   bd4af64405d844408e58df3c30c2f1c3    sample0020       roberta-base   \n",
       "72   d382d21e48d145bd829afc7e7e02dc2f    sample0020            e5-base   \n",
       "73   5004a30b8f6d4d82a4343b38b04d9b7b    sample0005            e5-base   \n",
       "74   b3b6e7c41c724c7785e4cae01cec5b4a    sample0005            e5-base   \n",
       "75   2ed9e40144754e4e80dc6b4eafcc2dd8    sample0010            e5-base   \n",
       "76   a6ee75d67baa497eaba6b69e3660d54c    sample0010       roberta-base   \n",
       "77   c000ce8521a54f44a945cbd2b975f01b    sample0020  all-mpnet-base-v2   \n",
       "78   49c4633c4a8d49f7ad64e521f6268504    sample0010  all-mpnet-base-v2   \n",
       "79   841aa8a827934dffa1e5bec5f9a806f9    sample0020  all-MiniLM-L12-v2   \n",
       "80   4ee98d3962254dd397d70c623254873f    sample0010            e5-base   \n",
       "81   90d91781574e493b9c514a5a6c091ccd    sample0020  all-mpnet-base-v2   \n",
       "82   4fde6e1d31fd4f8e9362a31e145e29bc    sample0010  all-MiniLM-L12-v2   \n",
       "83   e3041d7cabe44806bfcae229d77cbcfc    sample0005       roberta-base   \n",
       "84   8ea0f0d56fff4ea287ad7f6777b2c453    sample0005  all-mpnet-base-v2   \n",
       "85   561ad4da01424f59abf287aea7535542    sample0010  all-mpnet-base-v2   \n",
       "86   62cf5d41f7684f24ad27c616a08f01e6    sample0020   all-MiniLM-L6-v2   \n",
       "87   f6ff0c875f0a42928ceb03a3c8c571b4    sample0010   all-MiniLM-L6-v2   \n",
       "88   767d787c342947be9f41eb8189571476    sample0005  all-MiniLM-L12-v2   \n",
       "89   5dadc729930244548cc7804f3631e325    sample0005  all-mpnet-base-v2   \n",
       "90   eb31fa063fc34430af279035c150d797    sample0005   all-MiniLM-L6-v2   \n",
       "91   25e222843212478db3bf82975086f4c0    sample0020       roberta-base   \n",
       "92   5ddcaa5faf8b4f19aa5bd57da33ce6bb    sample0010       roberta-base   \n",
       "93   d1f01318b7484986a516735085149b9d    sample0005       roberta-base   \n",
       "94   c55fad823f18446b8e6a22f2db77d63c    sample0010  all-MiniLM-L12-v2   \n",
       "95   740dc87a66de4d109c1b51d89f181186    sample0020  all-MiniLM-L12-v2   \n",
       "96   d7c88cd0e48b432994c61464646aa00a    sample0020  all-MiniLM-L12-v2   \n",
       "97   de91dc68d9144ead80281d5c458d8da0    sample0010  all-MiniLM-L12-v2   \n",
       "98   04ec95cefe524ceaa706ab784c3829cc    sample0005  all-MiniLM-L12-v2   \n",
       "99   17ff2831d9854291b24bf5e79d4dc1d6    sample0005  all-MiniLM-L12-v2   \n",
       "100  1f572a02c14d4902996822b4869673f4    sample0020   all-MiniLM-L6-v2   \n",
       "101  de2c5787522d450c9e62ef822de945a5    sample0010   all-MiniLM-L6-v2   \n",
       "102  df33e092e8684999b8a209f3881bb510    sample0020   all-MiniLM-L6-v2   \n",
       "103  2cf351c4abf845b8a72078804eb048b3    sample0010   all-MiniLM-L6-v2   \n",
       "104  d8480740b4b0429d9ac50e22e4a92e70    sample0005   all-MiniLM-L6-v2   \n",
       "105  181408fce98949d097800f72b399f5d9    sample0005   all-MiniLM-L6-v2   \n",
       "\n",
       "                     model_name     AUC  amazonreviewsTestAUC  \n",
       "1            LogisticRegression  0.9948              0.994121  \n",
       "2            LogisticRegression  0.9946              0.994086  \n",
       "3            LogisticRegression  0.9948              0.994035  \n",
       "4            LogisticRegression  0.9955              0.993981  \n",
       "5            LogisticRegression  0.9942              0.993963  \n",
       "6    LinearDiscriminantAnalysis  0.9944              0.993794  \n",
       "7            LogisticRegression  0.9955              0.993728  \n",
       "8    LinearDiscriminantAnalysis  0.9942              0.993675  \n",
       "9    LinearDiscriminantAnalysis  0.9950              0.993651  \n",
       "10   LinearDiscriminantAnalysis  0.9944              0.993626  \n",
       "11   LinearDiscriminantAnalysis  0.9937              0.993600  \n",
       "12   LinearDiscriminantAnalysis  0.9947              0.993367  \n",
       "13                   GaussianNB  0.9937              0.993225  \n",
       "14                   GaussianNB  0.9939              0.993179  \n",
       "15                   GaussianNB  0.9947              0.993097  \n",
       "16         ExtraTreesClassifier  0.9938              0.992970  \n",
       "17         ExtraTreesClassifier  0.9932              0.992921  \n",
       "18         ExtraTreesClassifier  0.9946              0.992817  \n",
       "19   LinearDiscriminantAnalysis  0.9871              0.986415  \n",
       "20   LinearDiscriminantAnalysis  0.9871              0.985671  \n",
       "21   LinearDiscriminantAnalysis  0.9889              0.984945  \n",
       "22           LogisticRegression  0.9858              0.983672  \n",
       "23   LinearDiscriminantAnalysis  0.9855              0.983352  \n",
       "24           LogisticRegression  0.9852              0.983236  \n",
       "25   LinearDiscriminantAnalysis  0.9850              0.982760  \n",
       "26           LogisticRegression  0.9878              0.982534  \n",
       "27   LinearDiscriminantAnalysis  0.9871              0.981590  \n",
       "28   LinearDiscriminantAnalysis  0.9829              0.981262  \n",
       "29   LinearDiscriminantAnalysis  0.9821              0.980598  \n",
       "30           LogisticRegression  0.9807              0.979330  \n",
       "31   LinearDiscriminantAnalysis  0.9826              0.979148  \n",
       "32               LGBMClassifier  0.9803              0.978061  \n",
       "33           LogisticRegression  0.9787              0.977933  \n",
       "34               LGBMClassifier  0.9795              0.977437  \n",
       "35               LGBMClassifier  0.9804              0.976711  \n",
       "36               LGBMClassifier  0.9802              0.976441  \n",
       "37               LGBMClassifier  0.9819              0.975759  \n",
       "38           LogisticRegression  0.9773              0.975623  \n",
       "39               LGBMClassifier  0.9819              0.975599  \n",
       "40           LogisticRegression  0.9789              0.975254  \n",
       "41   GradientBoostingClassifier  0.9751              0.972498  \n",
       "42   GradientBoostingClassifier  0.9781              0.971171  \n",
       "43                SGDClassifier  0.9946              0.968797  \n",
       "44                SGDClassifier  0.9941              0.968197  \n",
       "45                SGDClassifier  0.9947              0.968147  \n",
       "46              RidgeClassifier  0.9940              0.966897  \n",
       "47              RidgeClassifier  0.9943              0.966897  \n",
       "48              RidgeClassifier  0.9944              0.966797  \n",
       "49              RidgeClassifier  0.9944              0.966647  \n",
       "50                SGDClassifier  0.9946              0.966597  \n",
       "51              RidgeClassifier  0.9952              0.966447  \n",
       "52              RidgeClassifier  0.9952              0.966397  \n",
       "53                SGDClassifier  0.9953              0.965997  \n",
       "54               LGBMClassifier  0.9664              0.964187  \n",
       "55                SGDClassifier  0.9954              0.963496  \n",
       "56               LGBMClassifier  0.9662              0.962955  \n",
       "57               LGBMClassifier  0.9667              0.961059  \n",
       "58           LogisticRegression  0.9570              0.955490  \n",
       "59   LinearDiscriminantAnalysis  0.9575              0.955122  \n",
       "60   LinearDiscriminantAnalysis  0.9599              0.954459  \n",
       "61           LogisticRegression  0.9583              0.954221  \n",
       "62   LinearDiscriminantAnalysis  0.9638              0.952514  \n",
       "63           LogisticRegression  0.9623              0.951660  \n",
       "64   LinearDiscriminantAnalysis  0.9569              0.950651  \n",
       "65           LogisticRegression  0.9565              0.950462  \n",
       "66   LinearDiscriminantAnalysis  0.9587              0.950326  \n",
       "67           LogisticRegression  0.9574              0.949447  \n",
       "68   LinearDiscriminantAnalysis  0.9603              0.947908  \n",
       "69           LogisticRegression  0.9593              0.945984  \n",
       "70                SGDClassifier  0.9858              0.939444  \n",
       "71              RidgeClassifier  0.9849              0.939294  \n",
       "72              RidgeClassifier  0.9857              0.938094  \n",
       "73              RidgeClassifier  0.9881              0.937744  \n",
       "74                SGDClassifier  0.9885              0.936694  \n",
       "75              RidgeClassifier  0.9852              0.936544  \n",
       "76              RidgeClassifier  0.9832              0.935744  \n",
       "77              RidgeClassifier  0.9824              0.934793  \n",
       "78              RidgeClassifier  0.9813              0.933043  \n",
       "79               LGBMClassifier  0.9355              0.932626  \n",
       "80                SGDClassifier  0.9856              0.931693  \n",
       "81                SGDClassifier  0.9802              0.931643  \n",
       "82               LGBMClassifier  0.9364              0.930276  \n",
       "83              RidgeClassifier  0.9839              0.929943  \n",
       "84              RidgeClassifier  0.9821              0.929743  \n",
       "85                SGDClassifier  0.9793              0.929493  \n",
       "86               LGBMClassifier  0.9367              0.929113  \n",
       "87               LGBMClassifier  0.9380              0.928945  \n",
       "88               LGBMClassifier  0.9394              0.927763  \n",
       "89                SGDClassifier  0.9807              0.927093  \n",
       "90               LGBMClassifier  0.9383              0.925930  \n",
       "91                SGDClassifier  0.9772              0.921792  \n",
       "92                SGDClassifier  0.9774              0.915692  \n",
       "93                SGDClassifier  0.9805              0.915692  \n",
       "94              RidgeClassifier  0.9596              0.888539  \n",
       "95              RidgeClassifier  0.9573              0.888339  \n",
       "96                SGDClassifier  0.9564              0.886889  \n",
       "97                SGDClassifier  0.9588              0.884888  \n",
       "98              RidgeClassifier  0.9636              0.884288  \n",
       "99                SGDClassifier  0.9630              0.882538  \n",
       "100             RidgeClassifier  0.9564              0.881738  \n",
       "101             RidgeClassifier  0.9582              0.880788  \n",
       "102               SGDClassifier  0.9554              0.880738  \n",
       "103               SGDClassifier  0.9576              0.878688  \n",
       "104             RidgeClassifier  0.9603              0.877038  \n",
       "105               SGDClassifier  0.9601              0.872887  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = [\n",
    "    'run_id',\n",
    "    'train_dataset',\n",
    "    'embedding_model',\n",
    "    'model_name',\n",
    "    #'amazonreviewsPredictionTime', a diferença do tempo de predição entre os classificadores é muito pequena\n",
    "    'AUC',\n",
    "    'amazonreviewsTestAUC'\n",
    "]\n",
    "\n",
    "filtered_mlflow_data = mlflow_data[columns_to_keep]\n",
    "filtered_mlflow_data = filtered_mlflow_data.sort_values(by='amazonreviewsTestAUC', ascending=False)\n",
    "filtered_mlflow_data.reset_index(inplace=True, drop=True)\n",
    "filtered_mlflow_data.index = filtered_mlflow_data.index + 1\n",
    "filtered_mlflow_data.to_excel(\"../reports/AmazonTrain_Results.xlsx\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "filtered_mlflow_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28528fe6",
   "metadata": {},
   "source": [
    "Entre os modelos avaliados, destacaram-se as combinações dos embeddings gte-small e bge-base-en-v1.5 com os classificadores Logistic Regression e Linear Discriminant Analysis, que apresentaram AUCs superiores a 0,993 nos dados de teste ('amazonreviewsTestAUC'), com alta estabilidade frente às variações no tamanho da amostra. Isso indica robustez mesmo com conjuntos de treino reduzidos.\n",
    "\n",
    "Embora tenhamos testado diferentes sample sizes (0,5%, 1% e 2%), os ganhos marginais entre eles foram mínimos entre os melhores modelos, o que justifica manter 0,5% como padrão, priorizando menor custo computacional e preservando a qualidade das predições.\n",
    "\n",
    "Modelos com embeddings como all-MiniLM e roberta-base mostraram desempenho inferior de forma consistente, independentemente do classificador ou sample size, o que os torna pouco indicados para o contexto atual.\n",
    "\n",
    "Apesar dos resultados apontarem com clareza os modelos mais promissores em termos de AUC, a escolha final para produção dependerá da análise do custo-benefício computacional dos embeddings, a ser realizada na sequência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11ea24",
   "metadata": {},
   "source": [
    "## Análise do Desempenho computacional dos embedders\n",
    "\n",
    "Considerando que a decisão final sobre os modelos envolve também critérios de custo-benefício computacional, avaliamos agora os principais aspectos de performance dos embedders em ambiente CPU (ambiente que nos estará disponível em produção): tempo de carregamento, latência online, tempo de codificação em lote, uso líquido de RAM, pico de memória e tamanho em disco. A análise será conduzida com diferentes tamanhos de batch e repetida múltiplas vezes para maior robustez nas médias. Os resultados serão utilizados como base para ponderar a viabilidade de produção de cada embedding_model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a7f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11364</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't Buy this book light This is a poorly des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>0</td>\n",
       "      <td>modem was in bad condition and did not work! T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1</td>\n",
       "      <td>The Greatest Superhero Movie of All Time Chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12572</th>\n",
       "      <td>1</td>\n",
       "      <td>Depravity driven home... I've recently watched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>1</td>\n",
       "      <td>EVERY SONG ROCKS They did something different!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                               text\n",
       "11364      0  Don't Buy this book light This is a poorly des...\n",
       "4119       0  modem was in bad condition and did not work! T...\n",
       "2008       1  The Greatest Superhero Movie of All Time Chris...\n",
       "12572      1  Depravity driven home... I've recently watched...\n",
       "4755       1  EVERY SONG ROCKS They did something different!..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_csv(\"../data/processed/train_amazonreviews_sample0005.csv\")\n",
    "df_sample = df_sample.sample(n=1000, random_state=42)\n",
    "print(df_sample.shape)\n",
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f60695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76150e573eb24eba92d2c7d071f6f584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding Models Analisados:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ AVISO: ram_usage_net_mb de 'all-mpnet-base-v2' batch_size=8 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_net_mb de 'all-mpnet-base-v2' batch_size=64 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_peak_mb de 'all-mpnet-base-v2' batch_size=64 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_net_mb de 'bge-base-en-v1.5' batch_size=64 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_net_mb de 'e5-base' batch_size=64 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_net_mb de 'gte-small' batch_size=64 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_net_mb de 'roberta-base' batch_size=8 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_net_mb de 'roberta-base' batch_size=32 foi 0 em todas as execuções. Ignorando média.\n",
      "⚠️ AVISO: ram_usage_net_mb de 'roberta-base' batch_size=64 foi 0 em todas as execuções. Ignorando média.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>load_time_sec</th>\n",
       "      <th>latency_online_sec</th>\n",
       "      <th>batch_time_sec</th>\n",
       "      <th>ram_usage_net_mb</th>\n",
       "      <th>ram_usage_peak_mb</th>\n",
       "      <th>model_size_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>8.66</td>\n",
       "      <td>21.59</td>\n",
       "      <td>22.37</td>\n",
       "      <td>87.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>12.76</td>\n",
       "      <td>25.39</td>\n",
       "      <td>25.39</td>\n",
       "      <td>87.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>12.78</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.25</td>\n",
       "      <td>87.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>13.33</td>\n",
       "      <td>10.96</td>\n",
       "      <td>11.18</td>\n",
       "      <td>128.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>13.62</td>\n",
       "      <td>37.20</td>\n",
       "      <td>37.20</td>\n",
       "      <td>87.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>13.96</td>\n",
       "      <td>13.50</td>\n",
       "      <td>9.04</td>\n",
       "      <td>87.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gte-small</td>\n",
       "      <td>64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>17.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>20.33</td>\n",
       "      <td>62.34</td>\n",
       "      <td>62.84</td>\n",
       "      <td>128.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>20.69</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.96</td>\n",
       "      <td>128.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>21.15</td>\n",
       "      <td>18.64</td>\n",
       "      <td>18.64</td>\n",
       "      <td>128.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all-MiniLM-L12-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>25.32</td>\n",
       "      <td>22.17</td>\n",
       "      <td>9.69</td>\n",
       "      <td>128.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gte-small</td>\n",
       "      <td>16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>27.64</td>\n",
       "      <td>8.70</td>\n",
       "      <td>5.80</td>\n",
       "      <td>128.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gte-small</td>\n",
       "      <td>8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>27.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>128.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gte-small</td>\n",
       "      <td>32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>28.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>128.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gte-small</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>30.97</td>\n",
       "      <td>26.77</td>\n",
       "      <td>8.95</td>\n",
       "      <td>128.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>42.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>44.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>418.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>47.65</td>\n",
       "      <td>13.93</td>\n",
       "      <td>14.11</td>\n",
       "      <td>418.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>64</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>49.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>480.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>49.90</td>\n",
       "      <td>75.61</td>\n",
       "      <td>25.33</td>\n",
       "      <td>418.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>52.21</td>\n",
       "      <td>18.55</td>\n",
       "      <td>12.81</td>\n",
       "      <td>418.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>52.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>418.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>53.27</td>\n",
       "      <td>54.45</td>\n",
       "      <td>18.18</td>\n",
       "      <td>480.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>54.93</td>\n",
       "      <td>18.82</td>\n",
       "      <td>12.99</td>\n",
       "      <td>418.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>55.79</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.20</td>\n",
       "      <td>418.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>55.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.32</td>\n",
       "      <td>418.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>8</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>58.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81</td>\n",
       "      <td>480.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>58.32</td>\n",
       "      <td>5.96</td>\n",
       "      <td>6.28</td>\n",
       "      <td>480.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>58.58</td>\n",
       "      <td>10.18</td>\n",
       "      <td>8.01</td>\n",
       "      <td>418.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>58.85</td>\n",
       "      <td>29.64</td>\n",
       "      <td>19.85</td>\n",
       "      <td>418.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>59.86</td>\n",
       "      <td>276.46</td>\n",
       "      <td>92.16</td>\n",
       "      <td>418.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>65.51</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.67</td>\n",
       "      <td>418.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>32</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>68.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.44</td>\n",
       "      <td>480.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>83.68</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.42</td>\n",
       "      <td>418.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>125.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>418.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  batch_size  load_time_sec  latency_online_sec  \\\n",
       "1    all-MiniLM-L6-v2          64           0.04              0.0155   \n",
       "2    all-MiniLM-L6-v2          16           0.04              0.0159   \n",
       "3    all-MiniLM-L6-v2           8           0.04              0.0158   \n",
       "4   all-MiniLM-L12-v2          64           0.06              0.0277   \n",
       "5    all-MiniLM-L6-v2          32           0.04              0.0157   \n",
       "6    all-MiniLM-L6-v2           1           0.04              0.0159   \n",
       "7           gte-small          64           0.12              0.0308   \n",
       "8   all-MiniLM-L12-v2          32           0.06              0.0279   \n",
       "9   all-MiniLM-L12-v2          16           0.06              0.0282   \n",
       "10  all-MiniLM-L12-v2           8           0.06              0.0278   \n",
       "11  all-MiniLM-L12-v2           1           0.06              0.0279   \n",
       "12          gte-small          16           0.12              0.0336   \n",
       "13          gte-small           8           0.12              0.0333   \n",
       "14          gte-small          32           0.12              0.0336   \n",
       "15          gte-small           1           0.12              0.0421   \n",
       "16  all-mpnet-base-v2          64           0.06              0.0514   \n",
       "17  all-mpnet-base-v2           8           0.06              0.0510   \n",
       "18  all-mpnet-base-v2           1           0.06              0.0530   \n",
       "19       roberta-base          64           0.11              0.0580   \n",
       "20  all-mpnet-base-v2          16           0.06              0.0513   \n",
       "21   bge-base-en-v1.5           1           0.06              0.0582   \n",
       "22   bge-base-en-v1.5          64           0.06              0.0591   \n",
       "23       roberta-base           1           0.11              0.0573   \n",
       "24            e5-base           1           0.06              0.0608   \n",
       "25            e5-base           8           0.06              0.0545   \n",
       "26   bge-base-en-v1.5           8           0.06              0.0557   \n",
       "27       roberta-base           8           0.11              0.0562   \n",
       "28       roberta-base          16           0.11              0.0555   \n",
       "29            e5-base          16           0.06              0.0542   \n",
       "30   bge-base-en-v1.5          16           0.06              0.0537   \n",
       "31  all-mpnet-base-v2          32           0.06              0.0506   \n",
       "32   bge-base-en-v1.5          32           0.06              0.0542   \n",
       "33       roberta-base          32           0.11              0.0588   \n",
       "34            e5-base          32           0.06              0.0545   \n",
       "35            e5-base          64           0.06              0.1289   \n",
       "\n",
       "    batch_time_sec  ram_usage_net_mb  ram_usage_peak_mb  model_size_mb  \n",
       "1             8.66             21.59              22.37          87.57  \n",
       "2            12.76             25.39              25.39          87.57  \n",
       "3            12.78              1.17               1.25          87.57  \n",
       "4            13.33             10.96              11.18         128.19  \n",
       "5            13.62             37.20              37.20          87.57  \n",
       "6            13.96             13.50               9.04          87.57  \n",
       "7            17.70               NaN               0.01         128.25  \n",
       "8            20.33             62.34              62.84         128.19  \n",
       "9            20.69             11.46              11.96         128.19  \n",
       "10           21.15             18.64              18.64         128.19  \n",
       "11           25.32             22.17               9.69         128.19  \n",
       "12           27.64              8.70               5.80         128.25  \n",
       "13           27.84              0.88               0.97         128.25  \n",
       "14           28.89              0.66               0.66         128.25  \n",
       "15           30.97             26.77               8.95         128.25  \n",
       "16           42.85               NaN                NaN         418.59  \n",
       "17           44.68               NaN               0.98         418.59  \n",
       "18           47.65             13.93              14.11         418.59  \n",
       "19           49.48               NaN               0.01         480.10  \n",
       "20           49.90             75.61              25.33         418.59  \n",
       "21           52.21             18.55              12.81         418.66  \n",
       "22           52.61               NaN               0.03         418.66  \n",
       "23           53.27             54.45              18.18         480.10  \n",
       "24           54.93             18.82              12.99         418.63  \n",
       "25           55.79              0.03               1.20         418.63  \n",
       "26           55.84              0.02               1.32         418.66  \n",
       "27           58.26               NaN               0.81         480.10  \n",
       "28           58.32              5.96               6.28         480.10  \n",
       "29           58.58             10.18               8.01         418.63  \n",
       "30           58.85             29.64              19.85         418.66  \n",
       "31           59.86            276.46              92.16         418.59  \n",
       "32           65.51              0.16               1.67         418.66  \n",
       "33           68.79               NaN               1.44         480.10  \n",
       "34           83.68              0.11               1.42         418.63  \n",
       "35          125.17               NaN               0.03         418.63  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df_sample[\"text\"].tolist()[:1000]\n",
    "models_dir = \"../models/sbert_models/\"\n",
    "model_names = [name for name in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, name))]\n",
    "\n",
    "batch_sizes = [1, 8, 16, 32, 64]\n",
    "n_runs = 3\n",
    "\n",
    "# Memória RAM atual (em MB)\n",
    "def get_memory_usage_mb():\n",
    "    gc.collect()\n",
    "    return psutil.Process(os.getpid()).memory_info().rss / (1024 ** 2)\n",
    "\n",
    "# Função para medir o uso máximo de memória (simulando \"pico\")\n",
    "def encode_and_measure_peak_memory(model, texts, bs):\n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_before = process.memory_info().rss / (1024 ** 2)\n",
    "\n",
    "    peak_memory = mem_before\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for t in range(0, len(texts), bs):\n",
    "        _ = model.encode(texts[t:t + bs], show_progress_bar=False)\n",
    "        current = process.memory_info().rss / (1024 ** 2)\n",
    "        peak_memory = max(peak_memory, current)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    mem_after = process.memory_info().rss / (1024 ** 2)\n",
    "    net_mem = max(mem_after - mem_before, 0)\n",
    "\n",
    "    return total_time, net_mem, peak_memory - mem_before\n",
    "\n",
    "results = []\n",
    "\n",
    "def safe_avg(lst, name):\n",
    "    if all(x == 0 for x in lst):\n",
    "        print(f\"⚠️ AVISO: {name} de '{model_name}' batch_size={bs} foi 0 em todas as execuções. Ignorando média.\")\n",
    "        return None\n",
    "    return sum(lst) / len([x for x in lst if x != 0])\n",
    "\n",
    "for model_name in tqdm(model_names, desc=\"Embedding Models Analisados\"):\n",
    "    model_path = os.path.join(models_dir, model_name)\n",
    "\n",
    "    # Medir tempo de carregamento\n",
    "    load_times = []\n",
    "    for _ in range(n_runs):\n",
    "        gc.collect()\n",
    "        start_time = time.time()\n",
    "        model = SentenceTransformer(model_path, device=\"cpu\")\n",
    "        load_times.append(time.time() - start_time)\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    if all(x == 0 for x in load_times):\n",
    "        print(f\"⚠️ AVISO: load_time de '{model_name}' foi 0 em todas as execuções. Ignorando média.\")\n",
    "        avg_load_time = None\n",
    "    else:\n",
    "        avg_load_time = sum(load_times) / len([x for x in load_times if x != 0])\n",
    "\n",
    "    # Tamanho do modelo em disco\n",
    "    model_size_bytes = sum(\n",
    "        os.path.getsize(os.path.join(root, f))\n",
    "        for root, _, files in os.walk(model_path)\n",
    "        for f in files\n",
    "    )\n",
    "    model_size_mb = model_size_bytes / (1024 ** 2)\n",
    "\n",
    "    model = SentenceTransformer(model_path, device=\"cpu\")\n",
    "\n",
    "    for bs in batch_sizes:\n",
    "        latencies, batch_times, ram_usages_net, ram_usages_peak = [], [], [], []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            # Latência online\n",
    "            gc.collect()\n",
    "            start_time = time.time()\n",
    "            for t in texts[:10]:\n",
    "                _ = model.encode(t, show_progress_bar=False)\n",
    "            latency = (time.time() - start_time) / 10\n",
    "            latencies.append(latency)\n",
    "\n",
    "            # RAM líquida + tempo + pico\n",
    "            try:\n",
    "                batch_time, ram_net, ram_peak = encode_and_measure_peak_memory(model, texts, bs)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao medir uso de memória para {model_name}, batch {bs}: {e}\")\n",
    "                batch_time, ram_net, ram_peak = 0, 0, 0\n",
    "\n",
    "            batch_times.append(batch_time)\n",
    "            ram_usages_net.append(ram_net)\n",
    "            ram_usages_peak.append(ram_peak)\n",
    "\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"batch_size\": bs,\n",
    "            \"load_time_sec\": round(avg_load_time, 2) if avg_load_time else None,\n",
    "            \"latency_online_sec\": round(safe_avg(latencies, \"latency_online_sec\"), 4) if safe_avg(latencies, \"latency_online_sec\") else None,\n",
    "            \"batch_time_sec\": round(safe_avg(batch_times, \"batch_time_sec\"), 2) if safe_avg(batch_times, \"batch_time_sec\") else None,\n",
    "            \"ram_usage_net_mb\": round(safe_avg(ram_usages_net, \"ram_usage_net_mb\"), 2) if safe_avg(ram_usages_net, \"ram_usage_net_mb\") else None,\n",
    "            \"ram_usage_peak_mb\": round(safe_avg(ram_usages_peak, \"ram_usage_peak_mb\"), 2) if safe_avg(ram_usages_peak, \"ram_usage_peak_mb\") else None,\n",
    "            \"model_size_mb\": round(model_size_mb, 2)\n",
    "        })\n",
    "\n",
    "embedders_info = pd.DataFrame(results)\n",
    "embedders_info=embedders_info.sort_values(\"batch_time_sec\")\n",
    "embedders_info.reset_index(inplace=True, drop=True)\n",
    "embedders_info.index = embedders_info.index + 1\n",
    "embedders_info.to_excel(\"../reports/Sbert_CPU_Benchmark.xlsx\")\n",
    "embedders_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da318de9",
   "metadata": {},
   "source": [
    "Apesar do all-MiniLM-L6-v2 apresentar a menor latência online e em batch entre todos os modelos testados, seu desempenho significativamente inferior em AUC o desqualifica para produção em comparação com o alto custo-benefício do gte-small que, mesmo com latência levemente superior, entrega AUCs robustos com baixo consumo de memória relativamente a outros modelos mais pesados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f3495",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "Diante das análises conduzidas, tanto sob a ótica da eficácia preditiva quanto sob critérios de viabilidade computacional, evidencia-se como escolha mais prudente para produção a combinação do embedder gte-small com o classificador Logistic Regression treinado a partir da amostra de 0,5% dos dados originais.\n",
    "\n",
    "Tal decisão se ancora, primeiramente, nos resultados superiores obtidos em termos de AUC nos dados de teste, consistentes mesmo sob variações no volume amostral — atributo que denota elevada robustez e estabilidade preditiva. Em particular, observou-se que ganhos marginais entre amostras de 0,5% a 2% são desprezíveis, o que legitima a adoção do menor sample size como padrão, maximizando a relação custo-benefício do processo.\n",
    "\n",
    "Adicionalmente, a avaliação de desempenho computacional corroborou essa escolha ao revelar que, embora não seja o modelo mais veloz em latência, o gte-small mantém um equilíbrio exemplar entre tempo de resposta, footprint de memória e tamanho em disco, superando largamente modelos mais custosos e menos eficazes como o roberta-base e o all-MiniLM.\n",
    "\n",
    "Assim, optamos, enquanto exclusivamente atentos à tarefa de predição de sentimento sobre reviews da Amazon, pela run de id 87d75ef72bad4c19946559891b71a013."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_final_tutoriamlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
