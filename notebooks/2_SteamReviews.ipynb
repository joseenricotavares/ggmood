{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98735111",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Após a escolha da implementação dos modelos sobre dados potencialmente diferentes do treino, i.e., a escolha por deixar de aplicar as predições sobre reviews de produtos da Amazon para então aplicar a reviews de jogos da Steam, consideramos a necessidade de estudo sobre a capacidade de generalização de nossos modelos para o tipo de review que aparecerá em produção, de modo a evitar possíveis problemas graves de Data Drift.\n",
    "\n",
    "Em caso de insatisfatoriedade da performance dos modelos nos dados da Steam, teremos de retreiná-los sobre as reviews da Steam.\n",
    "\n",
    "Dito isso, neste notebook, vamos realizar as seguintes tarefas: \n",
    "\n",
    "1) Obter e preparar dados de reviews da Steam para a validação (separando uma base de treino a ser utilizada em caso de necessidadade).\n",
    "\n",
    "2) A partir dos diversos modelos pré-treinados, embedar as reviews para validação em diferentes datasets de teste.\n",
    "\n",
    "3) Testar os 105 classificadores até então treinados nos datasets de teste obtidos.\n",
    "\n",
    "4) Avaliar o desempenho desses modelos no novo domínio, comparando suas métricas, especialmente AUC, entre os dados da Steam e da Amazon, com foco em identificar possíveis quedas significativas de performance.\n",
    "\n",
    "5) Caso a performance dos modelos pré-treinados se revele insatisfatória, retreinar os classificadores diretamente sobre embeddings das reviews da Steam, mantendo o mesmo rigor metodológico adotado anteriormente.\n",
    "\n",
    "6) Comparar os modelos treinados na Steam com os anteriores, buscando identificar qual abordagem entrega melhor generalização e custo-benefício para aplicação em produção.\n",
    "\n",
    "O objetivo final é selecionar o modelo mais adequado para lidar com reviews da Steam, assegurando estabilidade e eficácia do sistema preditivo em um cenário distinto do conjunto de treinamento original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a9afb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c02bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import mlflow\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src import reduce_text_df_per_class, PyCaretEmbeddingClassificationTrainer, BinaryClassificationEvaluator\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b403188",
   "metadata": {},
   "source": [
    "## Obter e preparar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888ad5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/steam-reviews\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = '../data/steam_data/raw'\n",
    "processed_data_path = '../data/steam_data/processed'\n",
    "os.makedirs(raw_data_path, exist_ok=True)\n",
    "os.makedirs(processed_data_path, exist_ok=True)\n",
    "\n",
    "kaggle_api = KaggleApi()\n",
    "kaggle_api.authenticate()\n",
    "kaggle_api.dataset_download_files('andrewmvd/steam-reviews', path=raw_data_path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882f8b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6417106, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6417106 entries, 0 to 6417105\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   app_id        int64 \n",
      " 1   app_name      object\n",
      " 2   review_text   object\n",
      " 3   review_score  int64 \n",
      " 4   review_votes  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 244.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(raw_data_path, 'dataset.csv'))\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69bdfcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Ruined my life.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This will be more of a ''my experience with th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>This game saved my virginity.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>• Do you like original games? • Do you like ga...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Easy to learn, hard to master.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_id        app_name                                        review_text  \\\n",
       "0      10  Counter-Strike                                    Ruined my life.   \n",
       "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
       "2      10  Counter-Strike                      This game saved my virginity.   \n",
       "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
       "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
       "\n",
       "   review_score  review_votes  \n",
       "0             1             0  \n",
       "1             1             1  \n",
       "2             1             0  \n",
       "3             1             0  \n",
       "4             1             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d52a8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_id               0\n",
      "app_name        183234\n",
      "review_text       7305\n",
      "review_score         0\n",
      "review_votes         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Verificando nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93c6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199e4f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_score\n",
      " 1    5126132\n",
      "-1    1100596\n",
      "Name: count, dtype: int64\n",
      "review_votes\n",
      "0    5313079\n",
      "1     913649\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['review_score'].value_counts())\n",
    "print(df['review_votes'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49dc650",
   "metadata": {},
   "source": [
    "De acordo com a página do kaggle:\n",
    "\n",
    "app_id = Game ID,\n",
    "\n",
    "app_name = Game Name,\n",
    "\n",
    "review_text = Review text,\n",
    "\n",
    "review_score = Review Sentiment: whether the game the review recommends the game or not,\n",
    "\n",
    "review_votes = Review vote: whether the review was recommended by another user or not.\n",
    "\n",
    "Bastanto atentar ao head, parece estar incorreto inferir diretamente sentimento positivo da recomendação de um player. Uma forma de reduzir a amostra e ao mesmo tempo filtrar reviews potencialmente mais consistentes em suas recomendações é excluir todas as reviews que não receberam votos. Faremos isso, além de adaptar a categoria review_score ao padrão de 0 e 1 para sentimentos positivo e negativo que viemos usando. Na sequência, usaremos estratégias de balanceamento e avaliaremos se o tamanho da amostra está conveniente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cebf735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(913649, 4)\n",
      "review_score\n",
      "1    649288\n",
      "0    264361\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[df['review_votes'] > 0]\n",
    "df = df.drop(columns=['review_votes'])\n",
    "df['review_score'] = df['review_score'].replace(-1, 0)\n",
    "\n",
    "print(df.shape)\n",
    "print(df['review_score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc4fe5",
   "metadata": {},
   "source": [
    "Vamos remover duplicatas em review_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1328b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661317, 4)\n",
      "review_score\n",
      "1    465875\n",
      "0    195442\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['review_text'])\n",
    "print(df.shape)\n",
    "print(df['review_score'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c38bc1",
   "metadata": {},
   "source": [
    "Uma técnica conveniente para que os nomes de games muito detestados ou muito amados pela comunidade não influenciem na análise de sentimento simplesmente por serem mencionados na review é substituir strings em review_text parecidas com o que consta na coluna app_name pela máscara genérica \"this game\". Vamos implementar essa técnica a seguir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f475d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes do masking:app_id                                                     105600\n",
      "app_name                                                 Terraria\n",
      "review_text     terraria is a good game even tho countless peo...\n",
      "review_score                                                    1\n",
      "Name: 77057, dtype: object\n",
      "Depois do masking:app_id                                                     105600\n",
      "app_name                                                 Terraria\n",
      "review_text     this game is a good game even tho countless pe...\n",
      "review_score                                                    1\n",
      "Name: 77057, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Função para substituir o nome do jogo por \"this game\"\n",
    "def mask_game_name(review_text, app_name):\n",
    "    if pd.isna(review_text) or pd.isna(app_name):\n",
    "        return review_text\n",
    "    # Escapar caracteres especiais no app_name para criar um padrão seguro de regex\n",
    "    escaped_app_name = re.escape(app_name)\n",
    "    # Substituir todas as ocorrências do app_name ignorando maiúsculas/minúsculas\n",
    "    pattern = re.compile(rf'\\b{escaped_app_name}\\b', flags=re.IGNORECASE)\n",
    "    return pattern.sub('this game', review_text)\n",
    "\n",
    "print(f\"Antes do masking:{df.iloc[10000]}\")\n",
    "df['review_text'] = df.apply(lambda row: mask_game_name(row['review_text'], row['app_name']), axis=1)\n",
    "print(f\"Depois do masking:{df.iloc[10000]}\")\n",
    "\n",
    "#dropando as colunas que não serão mais utilizadas\n",
    "df = df.drop(columns=['app_id','app_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449653e",
   "metadata": {},
   "source": [
    "## Underbalancing e Train/Test Split\n",
    "\n",
    "Utilizaremos os embeddings das reviews para reamostragem com o MinibatchKMeans, como feito anteriormente. O objetivo é manter a comparabilidade com os treinamentos realizados no sample de 0,5% dos dados da Amazon. Para isso, trabalharemos com 20.000 linhas simetricamente balanceadas entre treino e teste. O balanceamento será feito ajustando diretamente o número de clusters por classe, totalizando 40.000 linhas, a serem divididas entre treino e teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dbe447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 14:20:59,964 - INFO - Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f791992a6c743e9bb24374ecabfe786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2584 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 14:27:35,519 - INFO - Processing class: 1\n",
      "2025-05-05 14:27:35,745 - INFO - Class size: 465875 → Clusters: 20000\n",
      "2025-05-05 14:27:35,746 - INFO - Fitting MiniBatchKMeans...\n",
      "2025-05-05 14:47:27,367 - INFO - Processing class: 0\n",
      "2025-05-05 14:47:27,556 - INFO - Class size: 195442 → Clusters: 20000\n",
      "2025-05-05 14:47:27,557 - INFO - Fitting MiniBatchKMeans...\n",
      "2025-05-05 15:07:26,380 - INFO - Final reduced dataset size: (40000, 2)\n",
      "2025-05-05 15:07:26,386 - INFO - \n",
      "review_score\n",
      "0    20000\n",
      "1    20000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_reduced = reduce_text_df_per_class(\n",
    "    df=df,\n",
    "    class_column=\"review_score\",\n",
    "    embedding_input='review_text', #podemos informar a coluna com o texto no argumento para vetorização a partir da própria função\n",
    "    embedding_model_path=\"../models/sbert_models/all-MiniLM-L6-v2\",\n",
    "    device=device,\n",
    "    target_clusters=20000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ea883",
   "metadata": {},
   "source": [
    "Executaremos a separação de teste e treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061576dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição proporcional de 'review_score':\n",
      "\n",
      "Treino:\n",
      "review_score\n",
      "1    10000\n",
      "0    10000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Teste:\n",
      "review_score\n",
      "0    10000\n",
      "1    10000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df_reduced,\n",
    "    test_size=0.5,\n",
    "    stratify=df_reduced['review_score'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Exibir as proporções\n",
    "print(\"Distribuição proporcional de 'review_score':\")\n",
    "\n",
    "print(\"\\nTreino:\")\n",
    "print(df_train['review_score'].value_counts())\n",
    "\n",
    "print(\"\\nTeste:\")\n",
    "print(df_test['review_score'].value_counts())\n",
    "\n",
    "df_train.to_csv(\"../data/steam_data/processed/train_steamreviews_sample.csv\", index=False)\n",
    "df_test.to_csv(\"../data/steam_data/processed/test_steamreviews_sample.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87020a71",
   "metadata": {},
   "source": [
    "## Vetorizando os dados com Modelos Pré-Treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b893fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47b74d2d5ed488a8860dff0cc84d4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Modelos:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_dir = \"../models/sbert_models/\"\n",
    "data_dir = \"../data/steam_data/processed/\"\n",
    "output_dir = os.path.join(data_dir, \"embedded_data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "TEXT_COL = \"review_text\"\n",
    "CLASS_COL = \"review_score\"\n",
    "\n",
    "model_names = [m for m in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, m))]\n",
    "dataset_files = [f for f in os.listdir(data_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "for model_name in tqdm(model_names, desc=\"Modelos\"):\n",
    "    model = SentenceTransformer(os.path.join(models_dir, model_name), device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for dataset_file in dataset_files:\n",
    "        df = pd.read_csv(os.path.join(data_dir, dataset_file))\n",
    "\n",
    "        texts = df[TEXT_COL].astype(str).tolist()\n",
    "        embeddings = model.encode(texts, batch_size=256, show_progress_bar=False, normalize_embeddings=True)\n",
    "\n",
    "        emb_df = pd.DataFrame(embeddings, columns=[f\"CLS{i}\" for i in range(len(embeddings[0]))])\n",
    "        emb_df[TEXT_COL] = df[TEXT_COL]\n",
    "        emb_df[CLASS_COL] = df[CLASS_COL]\n",
    "\n",
    "        output_name = f\"{os.path.splitext(dataset_file)[0]}_{model_name}.csv\"\n",
    "        emb_df.to_csv(os.path.join(output_dir, output_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8dc9ff",
   "metadata": {},
   "source": [
    "## Avaliação dos Classificadores do treinamento anterior sobre os dados da Steam\n",
    "\n",
    "Avaliaremos, antes de seguir com o treinamento, como os classificadores treinados sobre os dados da Amazon desempenham sobre o sentimento pertinente às reviews dos jogadores da Steam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d9fba9",
   "metadata": {},
   "source": [
    "Primeiro, conectamos ao servidor MLflow e recuperamos as execuções do experimento \"pycaret-embeddings-classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31674312",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment_id = mlflow.get_experiment_by_name(\"pycaret-embeddings-classification\").experiment_id\n",
    "runs = client.search_runs(experiment_ids=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245fe14",
   "metadata": {},
   "source": [
    "Aqui, preparamos os arquivos de dados e configuramos as variáveis necessárias para o processamento. Especificamos os diretórios e arquivos de dados, incluindo os arquivos de treino e teste, e configuramos quais colunas serão utilizadas no modelo, como a coluna alvo (review_score) e as colunas a serem descartadas (review_text).\n",
    "\n",
    "Esta célula será aproveitada também na iteração de treino sobre os dados da Steam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5496ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data_dir = \"../data/steam_data/processed/embedded_data\"\n",
    "target_column  = \"review_score\"\n",
    "drop_columns = [\"review_text\"]\n",
    "\n",
    "all_files = [f for f in os.listdir(embedded_data_dir) if f.endswith('.csv')]\n",
    "train_files = [f for f in all_files if f.startswith('train')]\n",
    "test_files = [f for f in all_files if f.startswith('test')]\n",
    "\n",
    "def get_embedder_suffix(filename):\n",
    "    return filename.split('_', 3)[-1]\n",
    "\n",
    "test_lookup = {get_embedder_suffix(f): f for f in test_files}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f923f",
   "metadata": {},
   "source": [
    "Nesta parte, buscamos os arquivos de teste e associamos cada um ao modelo treinado que foi utilizado para criar o embedding. Depois, usamos esses modelos para avaliar seu desempenho nos dados de teste, registrando os resultados de forma organizada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381a8c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1242f4e750424b51b86f1653b24fd568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets de Teste:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for suffix, test_file in tqdm(test_lookup.items(), desc='Datasets de Teste'):\n",
    "    \n",
    "    embedding_model_name = suffix.replace('.csv', '')\n",
    "    df_test = pd.read_csv(os.path.join(embedded_data_dir, test_file))\n",
    "    \n",
    "    # Filtrar apenas runs com o embedding model correspondente ao do dataset de teste\n",
    "    matching_runs = [\n",
    "        run for run in runs \n",
    "        if run.data.tags.get('embedding_model_name') == embedding_model_name\n",
    "    ]\n",
    "    \n",
    "    for run in matching_runs:\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "        with mlflow.start_run(run_id=run_id):\n",
    "            model_uri = f\"runs:/{run_id}/model\"\n",
    "            model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "            evaluator = BinaryClassificationEvaluator(\n",
    "                model=model,\n",
    "                test_dataset_name=test_file.replace('.csv', ''),\n",
    "                test_dataset_prefix=\"steamreviews\"\n",
    "            )\n",
    "\n",
    "            metrics = evaluator.evaluate_sklearn_model(\n",
    "                df_test,\n",
    "                target_column=target_column,\n",
    "                drop_columns=drop_columns\n",
    "            )\n",
    "\n",
    "            evaluator.log_to_mlflow(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840cebc3",
   "metadata": {},
   "source": [
    "Vamos agora extrair os dados sobre os modelos e suas métricas de desempenho, organizando essas informações em uma tabela para avaliar se houve quedas de desempenho de um tipo de review a outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5463d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>model_name</th>\n",
       "      <th>amazonreviewsTestAUC</th>\n",
       "      <th>steamreviewsTestAUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87d75ef72bad4c19946559891b71a013</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.993981</td>\n",
       "      <td>0.925512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f7b622218ef1454e94b8aa6f41c52807</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.993225</td>\n",
       "      <td>0.925449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>db866db06979460b84ca82b283ff9bf5</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>0.925390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04640f874deb4c73bca58a1a3ff35b09</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.992970</td>\n",
       "      <td>0.925352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b3ebca80e8d34cbcbe6f383cdc61246a</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.993097</td>\n",
       "      <td>0.925264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9212f59735a3429584ba058798a3f8ad</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.994086</td>\n",
       "      <td>0.924350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c604ce41a58f4cfa8402e615984f2e16</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.994121</td>\n",
       "      <td>0.924344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f54c5bc5c20b4badaccb667433c0b02c</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.992921</td>\n",
       "      <td>0.923971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fdbb7d2336d344a582e4d304555711b0</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.993728</td>\n",
       "      <td>0.923863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c3c694ffacfb40bf8d15d3bd898fbadf</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.992817</td>\n",
       "      <td>0.923507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4e61c3ec196444cb94f92d652a9072a6</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.994035</td>\n",
       "      <td>0.923254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eb3845d7e64d41908941924bf006e325</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.922399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>92262b01288749b6b691712e497c9781</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.993963</td>\n",
       "      <td>0.922022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>512a0882ecae4f47b3e524a64f5fc987</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993794</td>\n",
       "      <td>0.921371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>766f158e433d4942ad6463409a6f1813</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993626</td>\n",
       "      <td>0.920785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7494240945774d4885516e5565356223</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993675</td>\n",
       "      <td>0.919401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1497bd8e723a40d089e04f5035a5c898</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993367</td>\n",
       "      <td>0.919150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78970659732742dc8661e50da0f1abd6</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993600</td>\n",
       "      <td>0.917151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>696c3299c34d499c876d6322757c9057</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.983672</td>\n",
       "      <td>0.878008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>d0436ba95d894dc4a825a6d6177ad4e0</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>0.877949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9224e8535ee148d18170b2a05e695703</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.982534</td>\n",
       "      <td>0.877924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1b92e457051a438d863b3e3265f08c63</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.981590</td>\n",
       "      <td>0.877023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>89bdbc62218641cfacb29341f33caafa</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.982760</td>\n",
       "      <td>0.873974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4413244dd7084cc4a8db4b79a8b13ca6</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.983352</td>\n",
       "      <td>0.873378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>efc9885680444a4a8f8888546a7838b3</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.975599</td>\n",
       "      <td>0.869497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1b8bf80f4da84607901a8a3b6d8cc414</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.976711</td>\n",
       "      <td>0.868816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b7d3c5f50b164203afe9b32280b40a4e</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.976441</td>\n",
       "      <td>0.867457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6083627879b142a79965e31c6a8f7093</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.986415</td>\n",
       "      <td>0.859457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9b65da2d4a004e3bbc62b69b7c67b2cb</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.858331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>e8ba1233ab5c48839610fbb8a60825b5</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.975254</td>\n",
       "      <td>0.857442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              run_id train_dataset    embedding_model  \\\n",
       "1   87d75ef72bad4c19946559891b71a013    sample0005          gte-small   \n",
       "2   f7b622218ef1454e94b8aa6f41c52807    sample0010          gte-small   \n",
       "3   db866db06979460b84ca82b283ff9bf5    sample0020          gte-small   \n",
       "4   04640f874deb4c73bca58a1a3ff35b09    sample0020   bge-base-en-v1.5   \n",
       "5   b3ebca80e8d34cbcbe6f383cdc61246a    sample0005          gte-small   \n",
       "6   9212f59735a3429584ba058798a3f8ad    sample0010          gte-small   \n",
       "7   c604ce41a58f4cfa8402e615984f2e16    sample0020          gte-small   \n",
       "8   f54c5bc5c20b4badaccb667433c0b02c    sample0010   bge-base-en-v1.5   \n",
       "9   fdbb7d2336d344a582e4d304555711b0    sample0005   bge-base-en-v1.5   \n",
       "10  c3c694ffacfb40bf8d15d3bd898fbadf    sample0005   bge-base-en-v1.5   \n",
       "11  4e61c3ec196444cb94f92d652a9072a6    sample0020   bge-base-en-v1.5   \n",
       "12  eb3845d7e64d41908941924bf006e325    sample0005          gte-small   \n",
       "13  92262b01288749b6b691712e497c9781    sample0010   bge-base-en-v1.5   \n",
       "14  512a0882ecae4f47b3e524a64f5fc987    sample0020          gte-small   \n",
       "15  766f158e433d4942ad6463409a6f1813    sample0010          gte-small   \n",
       "16  7494240945774d4885516e5565356223    sample0020   bge-base-en-v1.5   \n",
       "17  1497bd8e723a40d089e04f5035a5c898    sample0005   bge-base-en-v1.5   \n",
       "18  78970659732742dc8661e50da0f1abd6    sample0010   bge-base-en-v1.5   \n",
       "19  696c3299c34d499c876d6322757c9057    sample0020            e5-base   \n",
       "20  d0436ba95d894dc4a825a6d6177ad4e0    sample0010            e5-base   \n",
       "21  9224e8535ee148d18170b2a05e695703    sample0005            e5-base   \n",
       "22  1b92e457051a438d863b3e3265f08c63    sample0005            e5-base   \n",
       "23  89bdbc62218641cfacb29341f33caafa    sample0010            e5-base   \n",
       "24  4413244dd7084cc4a8db4b79a8b13ca6    sample0020            e5-base   \n",
       "25  efc9885680444a4a8f8888546a7838b3    sample0005            e5-base   \n",
       "26  1b8bf80f4da84607901a8a3b6d8cc414    sample0020            e5-base   \n",
       "27  b7d3c5f50b164203afe9b32280b40a4e    sample0010            e5-base   \n",
       "28  6083627879b142a79965e31c6a8f7093    sample0020       roberta-base   \n",
       "29  9b65da2d4a004e3bbc62b69b7c67b2cb    sample0005       roberta-base   \n",
       "30  e8ba1233ab5c48839610fbb8a60825b5    sample0005  all-mpnet-base-v2   \n",
       "\n",
       "                    model_name  amazonreviewsTestAUC  steamreviewsTestAUC  \n",
       "1           LogisticRegression              0.993981             0.925512  \n",
       "2                   GaussianNB              0.993225             0.925449  \n",
       "3                   GaussianNB              0.993179             0.925390  \n",
       "4         ExtraTreesClassifier              0.992970             0.925352  \n",
       "5                   GaussianNB              0.993097             0.925264  \n",
       "6           LogisticRegression              0.994086             0.924350  \n",
       "7           LogisticRegression              0.994121             0.924344  \n",
       "8         ExtraTreesClassifier              0.992921             0.923971  \n",
       "9           LogisticRegression              0.993728             0.923863  \n",
       "10        ExtraTreesClassifier              0.992817             0.923507  \n",
       "11          LogisticRegression              0.994035             0.923254  \n",
       "12  LinearDiscriminantAnalysis              0.993651             0.922399  \n",
       "13          LogisticRegression              0.993963             0.922022  \n",
       "14  LinearDiscriminantAnalysis              0.993794             0.921371  \n",
       "15  LinearDiscriminantAnalysis              0.993626             0.920785  \n",
       "16  LinearDiscriminantAnalysis              0.993675             0.919401  \n",
       "17  LinearDiscriminantAnalysis              0.993367             0.919150  \n",
       "18  LinearDiscriminantAnalysis              0.993600             0.917151  \n",
       "19          LogisticRegression              0.983672             0.878008  \n",
       "20          LogisticRegression              0.983236             0.877949  \n",
       "21          LogisticRegression              0.982534             0.877924  \n",
       "22  LinearDiscriminantAnalysis              0.981590             0.877023  \n",
       "23  LinearDiscriminantAnalysis              0.982760             0.873974  \n",
       "24  LinearDiscriminantAnalysis              0.983352             0.873378  \n",
       "25              LGBMClassifier              0.975599             0.869497  \n",
       "26              LGBMClassifier              0.976711             0.868816  \n",
       "27              LGBMClassifier              0.976441             0.867457  \n",
       "28  LinearDiscriminantAnalysis              0.986415             0.859457  \n",
       "29  LinearDiscriminantAnalysis              0.984945             0.858331  \n",
       "30          LogisticRegression              0.975254             0.857442  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_mlflow_metrics(runs, prefix_test_metric='amazonreviews'):\n",
    "\n",
    "    mlflow_data = []\n",
    "\n",
    "    for run in runs:\n",
    "        info = {}\n",
    "        info['run_id'] = run.info.run_id\n",
    "\n",
    "        # Tags\n",
    "        tags = run.data.tags\n",
    "        train_name = tags.get('train_dataset_name', '')\n",
    "        parts = train_name.split('_')\n",
    "        info['train_dataset'] = '_'.join(parts[2:3]) if len(parts) >= 3 else ''\n",
    "        info['embedding_model'] = tags.get('embedding_model_name')\n",
    "        info['model_name'] = tags.get('model_name')\n",
    "\n",
    "        # Métricas\n",
    "        for metric_name, value in run.data.metrics.items():\n",
    "            if metric_name.startswith('test'):\n",
    "                parts = metric_name.split('_')\n",
    "                new_metric_name = prefix_test_metric + '_'.join(parts[-1:])\n",
    "                info[new_metric_name] = value\n",
    "            else:\n",
    "                info[metric_name] = value\n",
    "\n",
    "        mlflow_data.append(info)\n",
    "\n",
    "    return pd.DataFrame(mlflow_data)\n",
    "\n",
    "mlflow_df = extract_mlflow_metrics(runs)\n",
    "\n",
    "print(mlflow_df.shape)\n",
    "\n",
    "columns = ['run_id', 'train_dataset', 'embedding_model', 'model_name', 'amazonreviewsTestAUC', 'steamreviewsTestAUC']\n",
    "filtered_mlflow_data = mlflow_df[columns].sort_values(by='steamreviewsTestAUC', ascending=False)\n",
    "filtered_mlflow_data.reset_index(inplace=True, drop=True)\n",
    "filtered_mlflow_data.index = filtered_mlflow_data.index + 1\n",
    "filtered_mlflow_data.to_excel(\"../reports/AmazonTrain_SteamTest.xlsx\")\n",
    "filtered_mlflow_data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd632594",
   "metadata": {},
   "source": [
    "Para nossa feliz surpresa a Regressão Logística campeã da última análise segue liderando entre os demais classificadores na AUC de teste também sobre os dados da Steam, e apesar de ter havido uma queda de performance, ela não foi muito alta, com a queda em apenas 0.07 pontos de AUC, e o mesmo pode-se dizer sobre a queda de performance dos demais classificadores, ao menos entre os top 15, que demonstraram capacidade maior de generalização evidentemente em virtude dos embedders subjacentes, bge-base-en-v1.5 e o gte-small.\n",
    "\n",
    "Poderíamos encerrar aqui a análise, mas temos interesse em investigar como nosso processo de treinamento se aplicado aos dados da Steam pode obter resultados distintos tanto no dataset de teste da Steam como no da Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084329",
   "metadata": {},
   "source": [
    "## Treino e avaliação dos classificadores sobre os dados da Steam\n",
    "\n",
    "Inicialmente vamos configurar o acesso aos dados vetorizados de teste da amazon para, na sequência, colocarmos em prática nossa pipeline de treino dos classificadores sobre os embeddings da Steam com teste em ambos os dados da Steam e da Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f909d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_embedded_data_dir = \"../data/processed/embedded_data\"\n",
    "amazon_target_column = 'class'\n",
    "amazon_drop_columns = ['text']\n",
    "\n",
    "amazon_all_files = [f for f in os.listdir(amazon_embedded_data_dir) if f.endswith('.csv')]\n",
    "amazon_test_files = {f.replace('train', 'test'): os.path.join(amazon_embedded_data_dir, f) for f in amazon_all_files if f.startswith('test')}\n",
    "\n",
    "amazon_test_lookup = {get_embedder_suffix(f): f for f in test_files}\n",
    "\n",
    "#Linha necessária devido à mudança do padrão no caso dos arquivos de teste da Amazon\n",
    "amazon_test_lookup = {k: v.replace(\"steamreviews_sample\", \"amazonreviews_sample0050\") for k, v in amazon_test_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d681af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295bdadefce0422f940910d3f039337f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets de Embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for train_file in tqdm(train_files, desc='Datasets de Embeddings'):\n",
    "    \n",
    "    suffix = get_embedder_suffix(train_file)\n",
    "    test_file = test_lookup.get(suffix)\n",
    "    amazon_test_file = amazon_test_lookup.get(suffix)\n",
    "\n",
    "    df_train = pd.read_csv(os.path.join(embedded_data_dir, train_file))\n",
    "    df_test = pd.read_csv(os.path.join(embedded_data_dir, test_file))\n",
    "    df_amazon = pd.read_csv(os.path.join(amazon_embedded_data_dir, amazon_test_file))\n",
    "\n",
    "    trainer = PyCaretEmbeddingClassificationTrainer(\n",
    "        train_dataset=df_train,\n",
    "        target_column=target_column,\n",
    "        drop_columns=drop_columns,  \n",
    "    )\n",
    "\n",
    "    trained_models = trainer.train()\n",
    "\n",
    "    run_ids = trainer.log_to_mlflow(\n",
    "        add_tags={\"train_dataset_name\": train_file.replace('.csv', ''),\n",
    "                \"embedding_model_name\": suffix.replace('.csv', ''),},\n",
    "    )\n",
    "    \n",
    "    for run_id in run_ids:\n",
    "\n",
    "        with mlflow.start_run(run_id=run_id):\n",
    "            model_uri = f\"runs:/{run_id}/model\"\n",
    "            model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "            evaluator = BinaryClassificationEvaluator(\n",
    "                model=model,\n",
    "                test_dataset_name=test_file.replace('.csv', ''),\n",
    "                test_dataset_prefix=\"steamreviews\"\n",
    "            )\n",
    "\n",
    "            metrics = evaluator.evaluate_sklearn_model(\n",
    "                df_test,\n",
    "                target_column=target_column,\n",
    "                drop_columns=drop_columns\n",
    "            )\n",
    "\n",
    "            evaluator.log_to_mlflow(metrics)\n",
    "\n",
    "            # Avaliação na Amazon\n",
    "            amazon_evaluator = BinaryClassificationEvaluator(\n",
    "                model=model,\n",
    "                test_dataset_name=amazon_test_file.replace('.csv', ''),\n",
    "                test_dataset_prefix=\"amazonreviews\"\n",
    "            )\n",
    "\n",
    "            amazon_metrics = amazon_evaluator.evaluate_sklearn_model(\n",
    "                df_amazon,\n",
    "                target_column=amazon_target_column,\n",
    "                drop_columns=amazon_drop_columns\n",
    "            )\n",
    "\n",
    "            amazon_evaluator.log_to_mlflow(amazon_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dba8d5",
   "metadata": {},
   "source": [
    "E aqui veremos as métricas resultantes, conforme acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d681b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>model_name</th>\n",
       "      <th>amazonreviewsTestAUC</th>\n",
       "      <th>steamreviewsTestAUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d63eafd08d7f41008759ed0f81efd71c</td>\n",
       "      <td>sample</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>0.941958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2b712e5b1544fd189b1746a58b70d94</td>\n",
       "      <td>sample</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.941911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a6e9481bcbb246938bc58996c09c82ed</td>\n",
       "      <td>sample</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.985695</td>\n",
       "      <td>0.939460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76bceb6b85914aa59da16f77472c86aa</td>\n",
       "      <td>sample</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.991654</td>\n",
       "      <td>0.939322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d791038f7ac945d391af8d25e27114de</td>\n",
       "      <td>sample</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.986206</td>\n",
       "      <td>0.938898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f30900751330402fbbebb89342c70666</td>\n",
       "      <td>sample</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.986664</td>\n",
       "      <td>0.937231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87d75ef72bad4c19946559891b71a013</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.993981</td>\n",
       "      <td>0.925512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f7b622218ef1454e94b8aa6f41c52807</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.993225</td>\n",
       "      <td>0.925449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>db866db06979460b84ca82b283ff9bf5</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>0.925390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>04640f874deb4c73bca58a1a3ff35b09</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.992970</td>\n",
       "      <td>0.925352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b3ebca80e8d34cbcbe6f383cdc61246a</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.993097</td>\n",
       "      <td>0.925264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9212f59735a3429584ba058798a3f8ad</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.994086</td>\n",
       "      <td>0.924350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c604ce41a58f4cfa8402e615984f2e16</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.994121</td>\n",
       "      <td>0.924344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>f54c5bc5c20b4badaccb667433c0b02c</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.992921</td>\n",
       "      <td>0.923971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fdbb7d2336d344a582e4d304555711b0</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.993728</td>\n",
       "      <td>0.923863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c3c694ffacfb40bf8d15d3bd898fbadf</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.992817</td>\n",
       "      <td>0.923507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4e61c3ec196444cb94f92d652a9072a6</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.994035</td>\n",
       "      <td>0.923254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eb3845d7e64d41908941924bf006e325</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.922399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>92262b01288749b6b691712e497c9781</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.993963</td>\n",
       "      <td>0.922022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>512a0882ecae4f47b3e524a64f5fc987</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993794</td>\n",
       "      <td>0.921371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>766f158e433d4942ad6463409a6f1813</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>gte-small</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993626</td>\n",
       "      <td>0.920785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7494240945774d4885516e5565356223</td>\n",
       "      <td>sample0020</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993675</td>\n",
       "      <td>0.919401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1497bd8e723a40d089e04f5035a5c898</td>\n",
       "      <td>sample0005</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993367</td>\n",
       "      <td>0.919150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>78970659732742dc8661e50da0f1abd6</td>\n",
       "      <td>sample0010</td>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.993600</td>\n",
       "      <td>0.917151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>f94a5d8b76c340a19946d0a9754fd004</td>\n",
       "      <td>sample</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.909614</td>\n",
       "      <td>0.915302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2943afbe8b6d45a381e08f9c23e7d1ea</td>\n",
       "      <td>sample</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.971687</td>\n",
       "      <td>0.914608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>93a46e4c54a841f7949461fed75491dc</td>\n",
       "      <td>sample</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.952475</td>\n",
       "      <td>0.913609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b5113d20a4af44b784d4ddfff2720101</td>\n",
       "      <td>sample</td>\n",
       "      <td>e5-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.954768</td>\n",
       "      <td>0.913035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b1a750ab8c084469b0f79fd9333aed5c</td>\n",
       "      <td>sample</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.943865</td>\n",
       "      <td>0.912712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>816944d7c96b4b4a958f7e407ab813db</td>\n",
       "      <td>sample</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.932944</td>\n",
       "      <td>0.912520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              run_id train_dataset    embedding_model  \\\n",
       "1   d63eafd08d7f41008759ed0f81efd71c        sample   bge-base-en-v1.5   \n",
       "2   f2b712e5b1544fd189b1746a58b70d94        sample   bge-base-en-v1.5   \n",
       "3   a6e9481bcbb246938bc58996c09c82ed        sample   bge-base-en-v1.5   \n",
       "4   76bceb6b85914aa59da16f77472c86aa        sample          gte-small   \n",
       "5   d791038f7ac945d391af8d25e27114de        sample          gte-small   \n",
       "6   f30900751330402fbbebb89342c70666        sample          gte-small   \n",
       "7   87d75ef72bad4c19946559891b71a013    sample0005          gte-small   \n",
       "8   f7b622218ef1454e94b8aa6f41c52807    sample0010          gte-small   \n",
       "9   db866db06979460b84ca82b283ff9bf5    sample0020          gte-small   \n",
       "10  04640f874deb4c73bca58a1a3ff35b09    sample0020   bge-base-en-v1.5   \n",
       "11  b3ebca80e8d34cbcbe6f383cdc61246a    sample0005          gte-small   \n",
       "12  9212f59735a3429584ba058798a3f8ad    sample0010          gte-small   \n",
       "13  c604ce41a58f4cfa8402e615984f2e16    sample0020          gte-small   \n",
       "14  f54c5bc5c20b4badaccb667433c0b02c    sample0010   bge-base-en-v1.5   \n",
       "15  fdbb7d2336d344a582e4d304555711b0    sample0005   bge-base-en-v1.5   \n",
       "16  c3c694ffacfb40bf8d15d3bd898fbadf    sample0005   bge-base-en-v1.5   \n",
       "17  4e61c3ec196444cb94f92d652a9072a6    sample0020   bge-base-en-v1.5   \n",
       "18  eb3845d7e64d41908941924bf006e325    sample0005          gte-small   \n",
       "19  92262b01288749b6b691712e497c9781    sample0010   bge-base-en-v1.5   \n",
       "20  512a0882ecae4f47b3e524a64f5fc987    sample0020          gte-small   \n",
       "21  766f158e433d4942ad6463409a6f1813    sample0010          gte-small   \n",
       "22  7494240945774d4885516e5565356223    sample0020   bge-base-en-v1.5   \n",
       "23  1497bd8e723a40d089e04f5035a5c898    sample0005   bge-base-en-v1.5   \n",
       "24  78970659732742dc8661e50da0f1abd6    sample0010   bge-base-en-v1.5   \n",
       "25  f94a5d8b76c340a19946d0a9754fd004        sample  all-mpnet-base-v2   \n",
       "26  2943afbe8b6d45a381e08f9c23e7d1ea        sample       roberta-base   \n",
       "27  93a46e4c54a841f7949461fed75491dc        sample            e5-base   \n",
       "28  b5113d20a4af44b784d4ddfff2720101        sample            e5-base   \n",
       "29  b1a750ab8c084469b0f79fd9333aed5c        sample       roberta-base   \n",
       "30  816944d7c96b4b4a958f7e407ab813db        sample  all-mpnet-base-v2   \n",
       "\n",
       "                    model_name  amazonreviewsTestAUC  steamreviewsTestAUC  \n",
       "1           LogisticRegression              0.990425             0.941958  \n",
       "2               LGBMClassifier              0.987676             0.941911  \n",
       "3   LinearDiscriminantAnalysis              0.985695             0.939460  \n",
       "4           LogisticRegression              0.991654             0.939322  \n",
       "5               LGBMClassifier              0.986206             0.938898  \n",
       "6         ExtraTreesClassifier              0.986664             0.937231  \n",
       "7           LogisticRegression              0.993981             0.925512  \n",
       "8                   GaussianNB              0.993225             0.925449  \n",
       "9                   GaussianNB              0.993179             0.925390  \n",
       "10        ExtraTreesClassifier              0.992970             0.925352  \n",
       "11                  GaussianNB              0.993097             0.925264  \n",
       "12          LogisticRegression              0.994086             0.924350  \n",
       "13          LogisticRegression              0.994121             0.924344  \n",
       "14        ExtraTreesClassifier              0.992921             0.923971  \n",
       "15          LogisticRegression              0.993728             0.923863  \n",
       "16        ExtraTreesClassifier              0.992817             0.923507  \n",
       "17          LogisticRegression              0.994035             0.923254  \n",
       "18  LinearDiscriminantAnalysis              0.993651             0.922399  \n",
       "19          LogisticRegression              0.993963             0.922022  \n",
       "20  LinearDiscriminantAnalysis              0.993794             0.921371  \n",
       "21  LinearDiscriminantAnalysis              0.993626             0.920785  \n",
       "22  LinearDiscriminantAnalysis              0.993675             0.919401  \n",
       "23  LinearDiscriminantAnalysis              0.993367             0.919150  \n",
       "24  LinearDiscriminantAnalysis              0.993600             0.917151  \n",
       "25  LinearDiscriminantAnalysis              0.909614             0.915302  \n",
       "26  LinearDiscriminantAnalysis              0.971687             0.914608  \n",
       "27  LinearDiscriminantAnalysis              0.952475             0.913609  \n",
       "28              LGBMClassifier              0.954768             0.913035  \n",
       "29              LGBMClassifier              0.943865             0.912712  \n",
       "30          LogisticRegression              0.932944             0.912520  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = client.search_runs(experiment_ids=experiment_id)\n",
    "mlflow_df = extract_mlflow_metrics(runs)\n",
    "print(mlflow_df.shape)\n",
    "\n",
    "columns = ['run_id', 'train_dataset', 'embedding_model', 'model_name', 'amazonreviewsTestAUC', 'steamreviewsTestAUC']\n",
    "filtered_mlflow_data = mlflow_df[columns].sort_values(by='steamreviewsTestAUC', ascending=False)\n",
    "filtered_mlflow_data.reset_index(inplace=True, drop=True)\n",
    "filtered_mlflow_data.index = filtered_mlflow_data.index + 1\n",
    "filtered_mlflow_data.to_excel(\"../reports/SteamTrain_Results.xlsx\")\n",
    "filtered_mlflow_data.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6367f69",
   "metadata": {},
   "source": [
    "Finalmente, o resultado foi que apenas por uma pequena diferença a regressão logística treinada sobre os dados vetorizados da Steam pelo gte-small superou o treinamento sobre os dados da Amazon. Como a queda de performance sobre os dados da Amazon não foi significativa, o modelo denota preferibilidade em termos de generalização para análise de sentimento de diferentes públicos com relação ao anterior, ainda que por pouco.\n",
    "\n",
    "Embora os primeiros lugares tenham cabido a três classificadores treinados em vetores da Steam obtido a partir do bge-base-en-v1.5, será no entanto à mencionada regressão logística que daremos o título de campeão do nosso experimento, uma vez que provou-se menos custoso em produção fazer uso de vetores do gte-small, e a diferença de performance entre ambos é mínima. O modelo que utilizaremos em produção já não sertá mais então o de run_id 87d75ef72bad4c19946559891b71a013, mas sim o quarto colocado da tabela acima, de run_id 76bceb6b85914aa59da16f77472c86aa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32435f6d",
   "metadata": {},
   "source": [
    "## Teste de predições a partir do modelo selecionado\n",
    "\n",
    "Faremos abaixo alguns testes de predição com o modelo selecionado, uma utilizando a biblioteca do mlflow para acessar o modelo, e outro fazendo uso do joblib, como alternativa sugerida pelo sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68b2c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo para cálculo dos embeddings com batch_size=8: 13.940841674804688 segundos.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "def get_df_embeddings(_embedding_model, text):\n",
    "    embeddings = _embedding_model.encode(text,batch_size=batch_size)\n",
    "    df_embeddings = pd.DataFrame(embeddings, columns=[f\"CLS{i}\" for i in range(embeddings.shape[1])])\n",
    "    return df_embeddings\n",
    "\n",
    "df = pd.read_csv(\"../data/steam_data/processed/test_steamreviews_sample.csv\")\n",
    "df = df.sample(1000, random_state=5).reset_index(drop=True)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "df_embeddings = get_df_embeddings(\n",
    "    _embedding_model=SentenceTransformer(\"../models/sbert_models/gte-small\",device='cpu'),\n",
    "    text=df[\"review_text\"].astype(str).tolist()\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Tempo para cálculo dos embeddings com batch_size={batch_size}: {end_time - start_time} segundos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd2e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhorando a exibição das reviews abaixo.\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08fd0a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love it, but hackers is a big problem</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445784</td>\n",
       "      <td>0.554216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R* has lost my support with the way they are treating the summer sale. No one gives a ♥♥♥♥ about in-game money attached to the sale with a -25% off tag. Awful way to run things.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977318</td>\n",
       "      <td>0.022682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Game! If you love classic 'Point and Click' Adventures,lovely designed Level and beautiful Music you shouldn't miss this game. The riddles may be confusing sometimes and need a certain amount of brain to solve but if you like to combine a snail with an envelope you will have no real problem but instead lots of fun.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026411</td>\n",
       "      <td>0.973589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most frustrating games I've ever played... And I can't stop! Love it.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211949</td>\n",
       "      <td>0.788051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Defense Grid is 'Babby's first Tower Defense' and possibly the ♥♥♥♥♥iest Tower Defense clone ever created. A pure pile of ♥♥♥♥. If you're looking for a Tower Defense game, play the original flash games or try the game Sanctum.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223798</td>\n",
       "      <td>0.776202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                          review_text  \\\n",
       "0                                                                                                                                                                                                                                                                                               Love it, but hackers is a big problem   \n",
       "1                                                                                                                                                   R* has lost my support with the way they are treating the summer sale. No one gives a ♥♥♥♥ about in-game money attached to the sale with a -25% off tag. Awful way to run things.   \n",
       "2  Great Game! If you love classic 'Point and Click' Adventures,lovely designed Level and beautiful Music you shouldn't miss this game. The riddles may be confusing sometimes and need a certain amount of brain to solve but if you like to combine a snail with an envelope you will have no real problem but instead lots of fun.   \n",
       "3                                                                                                                                                                                                                                                    One of the most frustrating games I've ever played... And I can't stop! Love it.   \n",
       "4                                                                                                  Defense Grid is 'Babby's first Tower Defense' and possibly the ♥♥♥♥♥iest Tower Defense clone ever created. A pure pile of ♥♥♥♥. If you're looking for a Tower Defense game, play the original flash games or try the game Sanctum.   \n",
       "\n",
       "   review_score  Label   Score_0   Score_1  \n",
       "0             1      1  0.445784  0.554216  \n",
       "1             0      0  0.977318  0.022682  \n",
       "2             1      1  0.026411  0.973589  \n",
       "3             1      1  0.211949  0.788051  \n",
       "4             0      1  0.223798  0.776202  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "\n",
    "model_uri = \"runs:/76bceb6b85914aa59da16f77472c86aa/model\"\n",
    "\n",
    "model_sklearn_call = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "preds = model_sklearn_call.predict(df_embeddings)\n",
    "probs = model_sklearn_call.predict_proba(df_embeddings)\n",
    "\n",
    "predictions_sklearn = pd.DataFrame({\n",
    "    'Label': preds,\n",
    "    'Score_0': probs[:, 0],\n",
    "    'Score_1': probs[:, 1]\n",
    "})\n",
    "\n",
    "predictions_sklearn = pd.concat([df[[\"review_text\", \"review_score\"]], predictions_sklearn], axis=1)\n",
    "predictions_sklearn.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b99b2cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love it, but hackers is a big problem</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445784</td>\n",
       "      <td>0.554216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R* has lost my support with the way they are treating the summer sale. No one gives a ♥♥♥♥ about in-game money attached to the sale with a -25% off tag. Awful way to run things.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977318</td>\n",
       "      <td>0.022682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Game! If you love classic 'Point and Click' Adventures,lovely designed Level and beautiful Music you shouldn't miss this game. The riddles may be confusing sometimes and need a certain amount of brain to solve but if you like to combine a snail with an envelope you will have no real problem but instead lots of fun.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026411</td>\n",
       "      <td>0.973589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most frustrating games I've ever played... And I can't stop! Love it.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211949</td>\n",
       "      <td>0.788051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Defense Grid is 'Babby's first Tower Defense' and possibly the ♥♥♥♥♥iest Tower Defense clone ever created. A pure pile of ♥♥♥♥. If you're looking for a Tower Defense game, play the original flash games or try the game Sanctum.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223798</td>\n",
       "      <td>0.776202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                          review_text  \\\n",
       "0                                                                                                                                                                                                                                                                                               Love it, but hackers is a big problem   \n",
       "1                                                                                                                                                   R* has lost my support with the way they are treating the summer sale. No one gives a ♥♥♥♥ about in-game money attached to the sale with a -25% off tag. Awful way to run things.   \n",
       "2  Great Game! If you love classic 'Point and Click' Adventures,lovely designed Level and beautiful Music you shouldn't miss this game. The riddles may be confusing sometimes and need a certain amount of brain to solve but if you like to combine a snail with an envelope you will have no real problem but instead lots of fun.   \n",
       "3                                                                                                                                                                                                                                                    One of the most frustrating games I've ever played... And I can't stop! Love it.   \n",
       "4                                                                                                  Defense Grid is 'Babby's first Tower Defense' and possibly the ♥♥♥♥♥iest Tower Defense clone ever created. A pure pile of ♥♥♥♥. If you're looking for a Tower Defense game, play the original flash games or try the game Sanctum.   \n",
       "\n",
       "   review_score  Label   Score_0   Score_1  \n",
       "0             1      1  0.445784  0.554216  \n",
       "1             0      0  0.977318  0.022682  \n",
       "2             1      1  0.026411  0.973589  \n",
       "3             1      1  0.211949  0.788051  \n",
       "4             0      1  0.223798  0.776202  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_path = r\"..\\mlruns\\294574624479352871\\76bceb6b85914aa59da16f77472c86aa\\artifacts\\model\\model.pkl\"\n",
    "model_sklearn_call = joblib.load(model_path) \n",
    "preds = model_sklearn_call.predict(df_embeddings)\n",
    "probs = model_sklearn_call.predict_proba(df_embeddings)\n",
    "\n",
    "predictions_sklearn = pd.DataFrame({\n",
    "    'Label': preds,\n",
    "    'Score_0': probs[:, 0],\n",
    "    'Score_1': probs[:, 1]\n",
    "})\n",
    "\n",
    "predictions_sklearn = pd.concat([df[[\"review_text\", \"review_score\"]], predictions_sklearn], axis=1)\n",
    "predictions_sklearn.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc44414",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Encerramos esta análise confirmando o objetivo central do notebook: investigar a generalização de modelos de análise de sentimento treinados sobre reviews da Amazon quando aplicados a dados da Steam, bem como avaliar o desempenho de modelos treinados diretamente sobre os dados desta última. Demonstramos que, embora exista uma leve queda de desempenho na transferência entre domínios, especialmente na métrica AUC, classificadores como a Regressão Logística — notadamente em embeddings como os do gte-small — sustentaram desempenho competitivo e com baixa perda de eficácia, destacando-se tanto em robustez quanto em custo computacional. Por fim, elegemos como modelo de produção aquele com run_id 76bceb6b85914aa59da16f77472c86aa, não apenas por sua performance consistente, mas também por seu equilíbrio entre eficiência e capacidade de generalização, com as métricas finais: amazonreviewsTestAUC=0.991654 e steamreviewsTestAUC=0.939322.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_final_tutoriamlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
